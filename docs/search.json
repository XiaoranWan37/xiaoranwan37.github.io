[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Xiaoran Wan",
    "section": "",
    "text": "University of California, San Diego | San Diego, CA\nM.S. in Business Analytics\nWestern Washington University | Bellingham, WA\nB.A. in Management Information Systems"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html",
    "href": "projects/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe dataset used in this replication is drawn directly from the publicly available archive provided by the original study.\n\n\nThe experiment adopted a natural field experiment design, meaning participants were unaware they were part of a study. This approach enhances the real-world applicability of the findings. The researchers tested three key variations in the fundraising letters:\n\nMatching grant vs. control: Whether the donor was informed that a lead donor would match their contribution.\nMatching ratio: Whether the match was offered at a 1:1, 2:1, or 3:1 rate.\nMatch threshold: Whether donors were told the lead donor would match contributions up to a specified threshold ($25,000, $50,000, or $100,000), or whether no such limit was mentioned.\n\nBy randomly assigning these treatments across a large sample, the researchers were able to isolate the causal effect of each letter feature on both the likelihood of donating and the average donation amount.\nThis replication aims to reproduce their findings using the same data."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#introduction",
    "href": "projects/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe dataset used in this replication is drawn directly from the publicly available archive provided by the original study.\n\n\nThe experiment adopted a natural field experiment design, meaning participants were unaware they were part of a study. This approach enhances the real-world applicability of the findings. The researchers tested three key variations in the fundraising letters:\n\nMatching grant vs. control: Whether the donor was informed that a lead donor would match their contribution.\nMatching ratio: Whether the match was offered at a 1:1, 2:1, or 3:1 rate.\nMatch threshold: Whether donors were told the lead donor would match contributions up to a specified threshold ($25,000, $50,000, or $100,000), or whether no such limit was mentioned.\n\nBy randomly assigning these treatments across a large sample, the researchers were able to isolate the causal effect of each letter feature on both the likelihood of donating and the average donation amount.\nThis replication aims to reproduce their findings using the same data."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#data",
    "href": "projects/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n1. Read the data into Python and describe the data\nI use data from Karlan and List (2007), which includes over 50,000 prior donors randomly assigned to different experimental conditions. The dataset includes:\n\nWhether the donor was assigned to a treatment (match offer) or control group\nThe match ratio: 1:1, 2:1, or 3:1\nThe match threshold: $25,000, $50,000, $100,000, or unstated\nThe suggested donation amount: either the same, 1.25×, or 1.5× the donor’s highest previous gift\n\nThese treatment dimensions allow us to examine how variation in messaging strategies affects:\n\nThe probability of making a donation\nThe amount donated (both conditional and unconditional on giving)\n\nThe data is loaded as follows:\n\nimport pandas as pd\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\nInterpretation\nThe preview of the dataset confirms that the experimental design was successfully implemented, with clear indicators for treatment assignment (treatment), match ratios (ratio, ratio2, ratio3), and threshold levels (size, size25, size50, size100, sizeno). Each donor record is further enriched with demographic and contextual variables—such as political geography (redcty, bluecty) and local racial composition (pwhite, pblack)—enabling a rich analysis of potential heterogeneity in response.\nThis structure supports causal inference by ensuring treatment assignment is randomized and well-encoded, which will be crucial when estimating treatment effects using both regression and t-test methodologies in the sections that follow.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n2. Balance Check: Verifying Group Equivalence Using t-Tests and Regressions on Baseline Covariates\nTo assess whether the randomization was successful, I examine whether the treatment and control groups differ significantly on several baseline characteristics that are not affected by the treatment. These variables are chosen to reflect the type of information shown in Table 1 of the original paper and include:\n\npwhite: proportion of population identifying as white\n\nave_hh_sz: average household size\n\npage18_39: proportion of population aged between 18 and 39\n\nmrm2: number of months since the donor’s most recent donation\n\nThe first three variables reflect demographic characteristics, while mrm2 captures behavioral engagement, specifically donor recency. All are pre-treatment measures, appropriate for testing balance.\nI use two complementary methods to evaluate balance:\n\nA t-test, which compares group means and assesses whether the differences are statistically significant.\n\nA simple linear regression, where each covariate is regressed on the treatment indicator.\n\nThese two methods should yield identical results in this setting because a two-sample t-test and a bivariate regression with a binary indicator are mathematically equivalent. Specifically:\n\nThe regression coefficient on treatment equals the difference in group means.\nThe t-statistic and p-value from the regression match the outputs of the t-test.\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Variables to test\nbalance_vars = ['pwhite', 'ave_hh_sz', 'page18_39', 'mrm2']\nresults = {}\n\nfor var in balance_vars:\n    df_clean = df[['treatment', var]].dropna()\n    treated = df_clean[df_clean['treatment'] == 1][var]\n    control = df_clean[df_clean['treatment'] == 0][var]\n    \n    # t-test\n    t_stat, p_val, _ = sm.stats.ttest_ind(treated, control)\n    \n    # regression\n    model = smf.ols(f\"{var} ~ treatment\", data=df_clean).fit()\n    \n    results[var] = {\n        \"T-stat (t-test)\": round(t_stat, 3),\n        \"P-value (t-test)\": round(p_val, 3),\n        \"Coeff (regression)\": round(model.params[\"treatment\"], 3),\n        \"P-value (regression)\": round(model.pvalues[\"treatment\"], 3)\n    }\n\nbalance_df = pd.DataFrame(results).T.reset_index().rename(columns={\"index\": \"Variable\"})\nbalance_df\n\n\n\n\n\n\n\n\nVariable\nT-stat (t-test)\nP-value (t-test)\nCoeff (regression)\nP-value (regression)\n\n\n\n\n0\npwhite\n-0.560\n0.575\n-0.001\n0.575\n\n\n1\nave_hh_sz\n0.824\n0.410\n0.003\n0.410\n\n\n2\npage18_39\n-0.124\n0.901\n-0.000\n0.901\n\n\n3\nmrm2\n0.119\n0.905\n0.014\n0.905\n\n\n\n\n\n\n\n\n\nInterpretation\nAs shown in the table above, the values of the t-tests and regressions are nearly identical for all four variables. All p-values are well above the 0.05 threshold, indicating no statistically significant differences between the treatment and control groups are all very small.\nFor instance, the difference in mrm2—the number of months since a donor’s most recent contribution—is only 0.014 months, with a p-value of 0.905. This further supports the conclusion that, prior to the intervention, the treatment and control groups were statistically similar in both demographic and behavioral characteristics.\nThese results confirm that randomization successfully created balanced groups, reducing the risk of confounding and supporting the internal validity of the experiment.\nTable 1 in the original paper serves the same purpose: to demonstrate that the experimental conditions were balanced at baseline. By confirming this balance, the authors—and I in this replication—help strengthen the credibility of the causal claims made in subsequent analyses."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#experimental-results",
    "href": "projects/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n3. Visual Comparison of Donation Rates Between Treatment and Control Groups\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# treatment vs control\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean().rename({0: \"Control\", 1: \"Treatment\"})\n\ndonation_rates.plot(\n    kind=\"bar\", \n    color=[\"#e0bbf9\", \"skyblue\"], \n    figsize=(7, 5), \n    width=0.5\n)\n\nplt.title(\"Proportion of Donors by Group\")\nplt.ylabel(\"Proportion Who Donated\")\nplt.xticks(rotation=0)\nplt.ylim(0, 0.03)\nplt.grid(axis='y', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThe bar chart offers initial descriptive evidence suggesting that matched donations may increase individuals’ likelihood of making a contribution. In particular, the treatment group—who were informed that their donations would be matched—shows a higher average donation rate compared to the control group.\nWhile the observed difference in proportions is relatively modest, its direction aligns with the hypothesis that matching offers act as a behavioral nudge. This preliminary pattern supports the rationale for conducting formal statistical tests to assess the robustness and significance of the effect.\nAccordingly, the following sections will apply inferential methods—including t-tests and regressions—to determine whether the observed difference is statistically significant and not due to random variation. This helps establish whether matching offers causally increase participation in charitable giving.\n\n\n4. Estimating the Effect of Treatment on Donation Likelihood Using T-Test and Regression\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Remove missing values for 'gave'\ndf_clean = df[[\"treatment\", \"gave\"]].dropna()\n\n# Split groups\ntreated = df_clean[df_clean[\"treatment\"] == 1][\"gave\"]\ncontrol = df_clean[df_clean[\"treatment\"] == 0][\"gave\"]\n\n# T-test\nt_stat, p_val, _ = sm.stats.ttest_ind(treated, control)\n\n# Regression\nmodel = smf.ols(\"gave ~ treatment\", data=df_clean).fit()\n\n# Summary table\ncomparison = {\n    \"T-stat (t-test)\": round(t_stat, 3),\n    \"P-value (t-test)\": round(p_val, 3),\n    \"Coeff (regression)\": round(model.params[\"treatment\"], 3),\n    \"P-value (regression)\": round(model.pvalues[\"treatment\"], 3),\n}\npd.DataFrame([comparison])\n\n\n\n\n\n\n\n\nT-stat (t-test)\nP-value (t-test)\nCoeff (regression)\nP-value (regression)\n\n\n\n\n0\n3.101\n0.002\n0.004\n0.002\n\n\n\n\n\n\n\n\n\nInterpretation\nThe statistical evidence presented here strongly supports the conclusion that receiving a matching grant offer significantly increases the likelihood of making a charitable donation.\nThe t-test results reveal a meaningful difference in donation rates between treatment and control groups, with a t-statistic of 3.101 and a p-value of 0.002. This p-value is well below the conventional 5% significance threshold, suggesting that the observed difference is unlikely to be due to random variation.\nA simple linear regression yields consistent results: the treatment coefficient is 0.004, indicating that individuals in the treatment group were, on average, 0.4 percentage points more likely to donate than those in the control group. The regression’s p-value of 0.002 further confirms the statistical significance of this effect.\nThese findings demonstrate the behavioral impact of a small but well-designed intervention. Even a modest incentive—simply informing donors of a matching offer—can shift behavior across a large population. This aligns with broader insights from behavioral economics: when individuals believe their actions are amplified through matching, they may feel a greater sense of urgency or efficacy, leading to higher participation rates.\nIn summary, the treatment intervention worked as intended. It increased donation rates in a statistically and practically significant way. The results not only replicate the findings of Karlan and List (2007) but also underscore how framing effects, when thoughtfully implemented, can powerfully influence real-world decision-making at scale.\n\n\n5. Replicating Table 3 with a Probit Model of Donation Likelihood\n\nimport pandas as pd\nimport statsmodels.api as sm\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Clean and prepare data\ndf_clean = df[[\"treatment\", \"gave\"]].dropna()\n\n# Add constant term\nX = sm.add_constant(df_clean[\"treatment\"])\ny = df_clean[\"gave\"]\n\n# Probit model\nprobit_model = sm.Probit(y, X).fit()\n\n# Display summary\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        16:58:43   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nInterpretation\nTo assess the robustness of the previous findings, I estimate a probit regression where the binary outcome is whether a charitable donation was made (gave), and the explanatory variable is assignment to the treatment group (treatment).\nThe model yields a treatment coefficient of 0.0868, which is positive and statistically significant at the 1% level (p = 0.002). This estimate replicates Table 3, Column 1 from Karlan and List (2007), offering additional support that matching donation offers increase the likelihood of giving.\nWhile the magnitude of a probit coefficient cannot be interpreted directly as a probability, the sign and statistical significance provide reliable evidence for the direction and presence of an effect. The result implies that even a minimal change in message framing—mentioning that a donation will be matched—can meaningfully shift donor behavior.\nTaken together, the probit results reinforce earlier t-test and linear regression findings. Across all models, the conclusion remains robust: a simple, low-cost intervention can enhance participation in charitable giving. This finding aligns with broader insights from behavioral economics, emphasizing that psychological framing can act as a powerful nudge in decision-making.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n6. Testing Whether Larger Match Ratios Increase Donation Rates\nTo examine whether the size of the match ratio affects donor response rates, I conduct a series of two-sample t-tests comparing the proportion of people who donated across three treatment arms: 1:1, 2:1, and 3:1 match ratios.\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport scipy.stats as stats\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Filter to only matched treatment groups (exclude control)\ndf_matched = df[df[\"treatment\"] == 1].dropna(subset=[\"gave\", \"ratio\"])\n\n# Convert ratio to numeric if needed (e.g., from \"1:1\" string to float 1.0)\ndf_matched[\"ratio\"] = pd.to_numeric(df_matched[\"ratio\"], errors=\"coerce\")\n\n# Create subsets for each match ratio group\ngave_1to1 = df_matched[df_matched[\"ratio\"] == 1.0][\"gave\"].dropna()\ngave_2to1 = df_matched[df_matched[\"ratio\"] == 2.0][\"gave\"].dropna()\ngave_3to1 = df_matched[df_matched[\"ratio\"] == 3.0][\"gave\"].dropna()\n\n# Safety check\nassert len(gave_1to1) &gt; 0, \"1:1 group is empty\"\nassert len(gave_2to1) &gt; 0, \"2:1 group is empty\"\nassert len(gave_3to1) &gt; 0, \"3:1 group is empty\"\n\n# T-tests\nt_2_vs_1, p_2_vs_1 = stats.ttest_ind(gave_2to1, gave_1to1)\nt_3_vs_1, p_3_vs_1 = stats.ttest_ind(gave_3to1, gave_1to1)\n\n# Summary table\nmatchrate_df = pd.DataFrame({\n    \"Comparison\": [\"2:1 vs 1:1\", \"3:1 vs 1:1\"],\n    \"T-statistic\": [round(t_2_vs_1, 3), round(t_3_vs_1, 3)],\n    \"P-value\": [round(p_2_vs_1, 3), round(p_3_vs_1, 3)]\n})\nmatchrate_df\n\n\n\n\n\n\n\n\nComparison\nT-statistic\nP-value\n\n\n\n\n0\n2:1 vs 1:1\n0.965\n0.335\n\n\n1\n3:1 vs 1:1\n1.015\n0.310\n\n\n\n\n\n\n\n\n\nInterpretation\nThe t-tests comparing different match ratios (2:1 vs 1:1 and 3:1 vs 1:1) reveal no statistically significant differences in donor response rates. Both comparisons yield p-values well above the conventional 5% threshold (0.335 and 0.310, respectively), indicating that increasing the match ratio does not significantly influence the likelihood of making a donation—at least within the scope of this experiment.\nThese findings support the authors’ observation on page 8 of the original paper: while offering a match may increase donations, the specific generosity of the match (1:1 vs 2:1 or 3:1) does not appear to matter. The behavioral nudge comes from the presence of a match itself, not its magnitude.\nFrom a behavioral economics perspective, this implies that a match—regardless of size—can effectively create perceived urgency or social validation. However, more generous matches do not seem to yield proportionally greater increases in participation.\nIn summary, although match offers boost donor engagement, increasing the match ratio does not further enhance giving. This reinforces the study’s broader insight: framing matters, but escalating incentives within that frame may not.\n\n\n7. Estimating the Effect of Match Ratios on Giving Using Regression Analysis\n\n\nRegression on Match Ratios\nTo complement the t-test comparison, I assess the effect of match ratio size using a regression approach. Specifically, I treat the 1:1 match group as the baseline and create dummy variables for the 2:1 and 3:1 match groups.\n\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\n# Load and clean data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_matched = df[df[\"treatment\"] == 1].dropna(subset=[\"gave\", \"ratio\"])\ndf_matched[\"ratio\"] = pd.to_numeric(df_matched[\"ratio\"], errors=\"coerce\")\n\n# Create dummy variables (1:1 as reference group)\ndf_matched[\"ratio2\"] = (df_matched[\"ratio\"] == 2).astype(int)\ndf_matched[\"ratio3\"] = (df_matched[\"ratio\"] == 3).astype(int)\n\n# Run regression\nmodel = smf.ols(\"gave ~ ratio2 + ratio3\", data=df_matched).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.524\nTime:                        16:58:43   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nInterpretation\nTo further evaluate the effect of match ratio size on charitable giving, I conducted an OLS regression using dummy variables for the 2:1 and 3:1 groups, with the 1:1 match group serving as the reference category. The dependent variable is whether a donation was made (gave), and the explanatory variables are ratio2 and ratio3.\nThe regression results show that neither ratio2 (coefficient = 0.0019, p = 0.338) nor ratio3 (coefficient = 0.0020, p = 0.313) has a statistically significant effect on donation likelihood compared to the 1:1 baseline. Both p-values are well above the conventional 0.05 threshold, and the estimated effects are close to zero, suggesting limited substantive impact.\nThese results align with the earlier t-tests, which also failed to detect any significant differences in donation rates between the groups. Taken together, the evidence indicates that while offering any match may increase participation, the size of the match—whether 1:1, 2:1, or 3:1—does not materially influence donor behavior.\nFrom a behavioral economics perspective, this reinforces the idea that the mere presence of a match can serve as a psychological nudge, perhaps by signaling social validation or urgency. However, increasing the match ratio does not appear to enhance this effect.\nThese findings support the authors’ suggestion that while framing matters in charitable appeals, the magnitude of what is offered within that frame may not. This further supports the view that perceived meaning, rather than material generosity, is often the more effective lever in shaping donor behavior.\n\n\n8. Comparing Response Rates Across Match Ratios: Direct Data vs. Regression Estimates\n\n\nResponse Rate Differences by Match Ratio\nTo further explore whether the size of the match ratio affects donation behavior, I compare response rates directly from the data and indirectly via regression coefficients.\nI calculate the observed response rate for each match ratio group:\n\n# Compute mean response rate by match ratio\nresponse_rates = df_matched.groupby(\"ratio\")[\"gave\"].mean().round(4)\nresponse_rates_df = response_rates.reset_index().rename(columns={\"gave\": \"Response Rate\", \"ratio\": \"Match Ratio\"})\nresponse_rates_df\n\n\n\n\n\n\n\n\nMatch Ratio\nResponse Rate\n\n\n\n\n0\n1\n0.0207\n\n\n1\n2\n0.0226\n\n\n2\n3\n0.0227\n\n\n\n\n\n\n\n\n\nInterpretation\nThe table summarizes the average donation response rates by match ratio group:\n\n1:1 match ratio group: 2.07%\n2:1 match ratio group: 2.26%\n3:1 match ratio group: 2.27%\n\nThe observed differences are small in magnitude: the 2:1 group exceeds the 1:1 group by 0.0019, and the 3:1 group by 0.0020. These values align precisely with the regression coefficients reported earlier (ratio2 = 0.0019, ratio3 = 0.0020), confirming consistency between model-based estimates and the raw summary statistics.\nYet, despite these numerical differences, the changes are neither statistically significant nor practically meaningful. The response rate barely shifts with more generous match ratios. This reinforces the idea that the effectiveness of a match offer lies in its presence—serving as a behavioral cue or social signal—rather than in its magnitude.\nIn short, while any match may nudge individuals to give, increasing the match ratio from 1:1 to 2:1 or 3:1 does not appear to yield additional persuasive power. This finding underscores a central insight from behavioral economics: framing matters, but the scale of generosity within that frame may not.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n9. Estimating the Impact of Treatment on Donation Amount Using T-Test and Regression\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Clean data (include all individuals: gave or not)\ndf_clean = df[[\"treatment\", \"amount\"]].dropna()\n\n# Run t-test\ntreated = df_clean[df_clean[\"treatment\"] == 1][\"amount\"]\ncontrol = df_clean[df_clean[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val, _ = sm.stats.ttest_ind(treated, control)\n\n# Run regression\nmodel = smf.ols(\"amount ~ treatment\", data=df_clean).fit()\n\n# Summary table\ncomparison = pd.DataFrame({\n    \"T-statistic (t-test)\": [round(t_stat, 3)],\n    \"P-value (t-test)\": [round(p_val, 3)],\n    \"Coeff (regression)\": [round(model.params[\"treatment\"], 3)],\n    \"P-value (regression)\": [round(model.pvalues[\"treatment\"], 3)]\n})\ncomparison\n\n\n\n\n\n\n\n\nT-statistic (t-test)\nP-value (t-test)\nCoeff (regression)\nP-value (regression)\n\n\n\n\n0\n1.861\n0.063\n0.154\n0.063\n\n\n\n\n\n\n\n\n\nInterpretation\nThis analysis examines whether assignment to the treatment group—i.e., receiving a matching donation offer—influences not only the likelihood of donating but also the amount donated. Both a t-test and a bivariate linear regression are used, with donation amount as the dependent variable.\nThe regression yields a treatment coefficient of 0.154, meaning that, on average, individuals in the treatment group donated $0.154 more than those in the control group. The associated p-value is 0.063, slightly above the conventional 5% significance threshold. The t-test produces consistent results, with a t-statistic of 1.861 and a p-value of 0.063.\nThese results suggest a modest positive effect of the treatment on donation size. However, the evidence is not statistically significant at the 95% confidence level. This means I cannot confidently reject the null hypothesis that the treatment had no effect, and the observed difference could plausibly be due to random variation.\nFrom a behavioral standpoint, these findings support the interpretation that the matching offer primarily functions as a nudge to increase participation, rather than a strong incentive to give more money. In other words, while the match offer may influence whether someone donates, it does not meaningfully affect how much they give once they have decided to donate.\n\n\n10. Estimating Conditional Treatment Effects on Donation Size Among Donors Only\n\n\nSize of Charitable Contribution (Conditional on Donating)\nTo analyze how treatment affects donation size conditional on giving, I restrict the dataset to individuals who made a positive donation, and repeat the t-test and linear regression.\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Filter to those who donated (amount &gt; 0)\ndf_gave = df[df[\"amount\"] &gt; 0][[\"treatment\", \"amount\"]].dropna()\n\n# T-test\ntreated = df_gave[df_gave[\"treatment\"] == 1][\"amount\"]\ncontrol = df_gave[df_gave[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val, _ = sm.stats.ttest_ind(treated, control)\n\n# Regression\nmodel = smf.ols(\"amount ~ treatment\", data=df_gave).fit()\n\n# Summary table\ncomparison_conditional = pd.DataFrame({\n    \"T-statistic (t-test)\": [round(t_stat, 3)],\n    \"P-value (t-test)\": [round(p_val, 3)],\n    \"Coeff (regression)\": [round(model.params[\"treatment\"], 3)],\n    \"P-value (regression)\": [round(model.pvalues[\"treatment\"], 3)]\n})\n\ncomparison_conditional\n\n\n\n\n\n\n\n\nT-statistic (t-test)\nP-value (t-test)\nCoeff (regression)\nP-value (regression)\n\n\n\n\n0\n-0.581\n0.561\n-1.668\n0.561\n\n\n\n\n\n\n\n\n\nInterpretation\nThis analysis isolates individuals who made a donation to examine whether the treatment influenced the amount donated, conditional on having given.\nThe regression yields a treatment coefficient of -1.668, indicating that donors in the treatment group gave, on average, $1.67 less than those in the control group. However, this difference is not statistically significant (p = 0.561), as corroborated by the t-test (t = -0.581, p = 0.561). These results suggest that any observed difference is likely attributable to random variation rather than a true effect.\nFrom a causal inference standpoint, the coefficient may still be interpreted causally, since treatment was randomly assigned. However, this is a conditional causal effect: it reflects the expected difference in donation amounts among those who donated, not across the full population.\nThis finding echoes earlier results. While treatment significantly increases the likelihood of donation, it does not influence how much individuals give once they decide to donate. Matching offers appear to act more as activation nudges—encouraging participation—rather than as mechanisms to increase donation intensity.\nIn short, treatment has no causal effect on the size of charitable contributions among donors. This underscores that behavioral elasticity lies more in the decision to give than in the amount given.\n\n\n11. Visualizing Donation Distributions and Mean Amounts for Treatment vs. Control Groups\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load and filter data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_gave = df[df[\"amount\"] &gt; 0].dropna(subset=[\"treatment\", \"amount\"])\n\n# Split groups\ntreated = df_gave[df_gave[\"treatment\"] == 1][\"amount\"]\ncontrol = df_gave[df_gave[\"treatment\"] == 0][\"amount\"]\n\n# Plot vertically\nfig, axes = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n\n# Control group\nsns.histplot(control, bins=30, kde=False, ax=axes[0], color=\"#e0bbf9\")\naxes[0].axvline(control.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean: {control.mean():.2f}\")\naxes[0].set_title(\"Control Group\")\naxes[0].set_ylabel(\"Count\")\naxes[0].legend()\n\n# Treatment group\nsns.histplot(treated, bins=30, kde=False, ax=axes[1], color=\"skyblue\")\naxes[1].axvline(treated.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean: {treated.mean():.2f}\")\naxes[1].set_title(\"Treatment Group\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].set_ylabel(\"Count\")\naxes[1].legend()\n\nplt.suptitle(\"Histogram of Donation Amounts (Conditional on Donating)\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThe histograms above display the distribution of donation amounts for individuals in the control and treatment groups, conditional on having donated.\nBoth groups exhibit right-skewed distributions, with most donations concentrated at lower amounts and a few large outliers. The red dashed vertical lines indicate the sample mean for each group: $45.54 for the control group and $43.87 for the treatment group.\nAlthough the control group shows a slightly higher mean donation, the gap—approximately $1.67—is small and statistically insignificant. This finding is consistent with earlier t-tests and regressions, and the visual similarity between the two distributions reinforces this conclusion.\nThese plots support the broader interpretation that matching offers influence whether someone donates, but not how much they give once they choose to contribute. The matching mechanism appears to act more as an activation nudge than a motivator for increased generosity, further emphasizing that framing—rather than financial magnitude—is the more powerful driver of behavior in this context."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#simulation-experiment",
    "href": "projects/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n12. Simulating the Law of Large Numbers: Cumulative Averages Converge Toward True Treatment Effect\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(0)\n\n# Simulate draws from Bernoulli distributions\nn_draws = 10000\ncontrol_draws = np.random.binomial(1, 0.018, size=n_draws)\ntreatment_draws = np.random.binomial(1, 0.022, size=n_draws)\n\n# Compute vector of differences and cumulative average\ndifferences = treatment_draws - control_draws\ncumulative_avg = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average Difference', color='teal')\nplt.axhline(y=0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title('Law of Large Numbers: Cumulative Average of Differences')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThe plot above illustrates the Law of Large Numbers through a simulated experiment. Each point represents the cumulative average of differences in donation rates between a treatment group (with p = 0.022) and a control group (with p = 0.018), based on successive pairs of random draws.\nInitially, the cumulative average fluctuates widely due to high variance in small samples. As the number of simulations increases, the cumulative average gradually stabilizes and converges toward the true difference in population means (0.004), indicated by the red dashed line.\nThis convergence captures a core insight from statistics: with a sufficiently large sample size, the average of noisy, individual differences reliably approximates the true population parameter. Even when individual draws are noisy, their aggregate behavior reveals the underlying structure.\nIn summary, the plot demonstrates that increasing the number of observations reduces estimation error. This empirical result validates the Law of Large Numbers and reinforces why large sample sizes are essential for reliable statistical inference.\n\n\n\nCentral Limit Theorem\n\n13. Visualizing the Central Limit Theorem: Sampling Distributions Become More Normal with Larger Samples\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(0)\n\n# Define parameters\ncontrol_p = 0.018\ntreatment_p = 0.022\nn_trials = 1000\nsample_sizes = [50, 200, 500, 1000]\n\n# Function to simulate one draw of average difference\ndef simulate_avg_diff(n, control_p, treatment_p):\n    control_sample = np.random.binomial(1, control_p, n)\n    treatment_sample = np.random.binomial(1, treatment_p, n)\n    return np.mean(treatment_sample) - np.mean(control_sample)\n\n# Create histograms for each sample size\nfig, axes = plt.subplots(len(sample_sizes), 1, figsize=(8, 10))\nfor i, n in enumerate(sample_sizes):\n    avg_diffs = [simulate_avg_diff(n, control_p, treatment_p) for _ in range(n_trials)]\n    axes[i].hist(avg_diffs, bins=30, color=\"skyblue\", edgecolor=\"black\")\n    axes[i].axvline(0, color=\"red\", linestyle=\"--\", label=\"Zero Line\")\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.suptitle(\"Central Limit Theorem: Sampling Distribution of Differences\", fontsize=14, y=1.02)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThese four histograms illustrate the sampling distribution of the average difference in donation rates between the treatment and control groups at increasing sample sizes, demonstrating the Central Limit Theorem in action.\n\nAt a sample size of 50, the distribution is relatively dispersed and exhibits heavier tails, deviating notably from a normal shape. However, the zero line remains roughly centered, indicating weak evidence of systematic differences between the groups.\nAt n = 200, the distribution becomes more concentrated and symmetric, increasingly resembling a normal distribution, though minor skewness is still evident.\nAt n = 500 and 1000, the distributions converge toward the classic bell-shaped curve with visibly smaller standard deviations, indicating improved precision in our estimates as sample size grows.\n\nIn all cases, the zero line remains close to the center of the distribution. This aligns with the theoretical expectation under the null hypothesis—namely, that the treatment and control groups differ only slightly. These visual results further validate earlier findings showing no meaningful treatment effect.\nOverall, these plots demonstrate the core principle of the Central Limit Theorem: even when underlying data follow a Bernoulli process, the sampling distribution of the mean difference approaches normality with sufficient sample size and repeated random sampling. This insight underlies the validity of using statistical techniques like t-tests and regression throughout this analysis."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#conclusion",
    "href": "projects/HW1/hw1_questions.html#conclusion",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Conclusion",
    "text": "Conclusion\nThis replication of Karlan and List (2007) reinforces several key insights about how small behavioral nudges can influence charitable giving.\nFrom the empirical analysis, I confirm that offering a matching donation significantly increases the likelihood that individuals make a contribution. However, the generosity of the match—whether 1:1, 2:1, or 3:1—has little additional effect. The presence of a match appears sufficient to activate giving behavior, but increasing the match size does not meaningfully amplify this effect.\nMoreover, while the treatment increases the probability of donation, it does not significantly affect how much individuals give once they decide to donate. This suggests that matching works more as a trigger for participation than as an incentive for larger gifts.\nThe simulation experiments provide a deeper understanding of the statistical tools used. The Law of Large Numbers shows how repeated sampling reveals stable patterns, while the Central Limit Theorem justifies the use of t-tests and regressions by demonstrating the emergence of normality in sampling distributions.\nTogether, these findings affirm both the behavioral and statistical logic behind the original study—and highlight how even simple message framing can shift real-world outcomes in meaningful, measurable ways. Overall, the findings serve as a reminder that thoughtful design—both in messaging and in methodology—can illuminate powerful patterns in human behavior.\n[End of this Page]"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nXiaoran Wan\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  }
]