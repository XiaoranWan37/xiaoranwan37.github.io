[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Xiaoran Wan",
    "section": "",
    "text": "University of California, San Diego | San Diego, CA\nM.S. in Business Analytics\nWestern Washington University | Bellingham, WA\nB.A. in Management Information Systems"
  },
  {
    "objectID": "projects/HW1/hw1_questions.html",
    "href": "projects/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe dataset used in this replication is drawn directly from the publicly available archive provided by the original study.\n\n\nThe experiment adopted a natural field experiment design, meaning participants were unaware they were part of a study. This approach enhances the real-world applicability of the findings. The researchers tested three key variations in the fundraising letters:\n\nMatching grant vs. control: Whether the donor was informed that a lead donor would match their contribution.\nMatching ratio: Whether the match was offered at a 1:1, 2:1, or 3:1 rate.\nMatch threshold: Whether donors were told the lead donor would match contributions up to a specified threshold ($25,000, $50,000, or $100,000), or whether no such limit was mentioned.\n\nBy randomly assigning these treatments across a large sample, the researchers were able to isolate the causal effect of each letter feature on both the likelihood of donating and the average donation amount.\nThis replication aims to reproduce their findings using the same data."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#introduction",
    "href": "projects/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe dataset used in this replication is drawn directly from the publicly available archive provided by the original study.\n\n\nThe experiment adopted a natural field experiment design, meaning participants were unaware they were part of a study. This approach enhances the real-world applicability of the findings. The researchers tested three key variations in the fundraising letters:\n\nMatching grant vs. control: Whether the donor was informed that a lead donor would match their contribution.\nMatching ratio: Whether the match was offered at a 1:1, 2:1, or 3:1 rate.\nMatch threshold: Whether donors were told the lead donor would match contributions up to a specified threshold ($25,000, $50,000, or $100,000), or whether no such limit was mentioned.\n\nBy randomly assigning these treatments across a large sample, the researchers were able to isolate the causal effect of each letter feature on both the likelihood of donating and the average donation amount.\nThis replication aims to reproduce their findings using the same data."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#data",
    "href": "projects/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n1. Read the data into Python and describe the data\nI use data from Karlan and List (2007), which includes over 50,000 prior donors randomly assigned to different experimental conditions. The dataset includes:\n\nWhether the donor was assigned to a treatment (match offer) or control group\nThe match ratio: 1:1, 2:1, or 3:1\nThe match threshold: $25,000, $50,000, $100,000, or unstated\nThe suggested donation amount: either the same, 1.25×, or 1.5× the donor’s highest previous gift\n\nThese treatment dimensions allow us to examine how variation in messaging strategies affects:\n\nThe probability of making a donation\nThe amount donated (both conditional and unconditional on giving)\n\nThe data is loaded as follows:\n\nimport pandas as pd\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\nInterpretation\nThe preview of the dataset confirms that the experimental design was successfully implemented, with clear indicators for treatment assignment (treatment), match ratios (ratio, ratio2, ratio3), and threshold levels (size, size25, size50, size100, sizeno). Each donor record is further enriched with demographic and contextual variables—such as political geography (redcty, bluecty) and local racial composition (pwhite, pblack)—enabling a rich analysis of potential heterogeneity in response.\nThis structure supports causal inference by ensuring treatment assignment is randomized and well-encoded, which will be crucial when estimating treatment effects using both regression and t-test methodologies in the sections that follow.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n2. Balance Check: Verifying Group Equivalence Using t-Tests and Regressions on Baseline Covariates\nTo assess whether the randomization was successful, I examine whether the treatment and control groups differ significantly on several baseline characteristics that are not affected by the treatment. These variables are chosen to reflect the type of information shown in Table 1 of the original paper and include:\n\npwhite: proportion of population identifying as white\n\nave_hh_sz: average household size\n\npage18_39: proportion of population aged between 18 and 39\n\nmrm2: number of months since the donor’s most recent donation\n\nThe first three variables reflect demographic characteristics, while mrm2 captures behavioral engagement, specifically donor recency. All are pre-treatment measures, appropriate for testing balance.\nI use two complementary methods to evaluate balance:\n\nA t-test, which compares group means and assesses whether the differences are statistically significant.\n\nA simple linear regression, where each covariate is regressed on the treatment indicator.\n\nThese two methods should yield identical results in this setting because a two-sample t-test and a bivariate regression with a binary indicator are mathematically equivalent. Specifically:\n\nThe regression coefficient on treatment equals the difference in group means.\nThe t-statistic and p-value from the regression match the outputs of the t-test.\n\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Variables to test\nbalance_vars = ['pwhite', 'ave_hh_sz', 'page18_39', 'mrm2']\nresults = {}\n\nfor var in balance_vars:\n    df_clean = df[['treatment', var]].dropna()\n    treated = df_clean[df_clean['treatment'] == 1][var]\n    control = df_clean[df_clean['treatment'] == 0][var]\n    \n    # t-test\n    t_stat, p_val, _ = sm.stats.ttest_ind(treated, control)\n    \n    # regression\n    model = smf.ols(f\"{var} ~ treatment\", data=df_clean).fit()\n    \n    results[var] = {\n        \"T-stat (t-test)\": round(t_stat, 3),\n        \"P-value (t-test)\": round(p_val, 3),\n        \"Coeff (regression)\": round(model.params[\"treatment\"], 3),\n        \"P-value (regression)\": round(model.pvalues[\"treatment\"], 3)\n    }\n\nbalance_df = pd.DataFrame(results).T.reset_index().rename(columns={\"index\": \"Variable\"})\nbalance_df\n\n\n\n\n\n\n\n\nVariable\nT-stat (t-test)\nP-value (t-test)\nCoeff (regression)\nP-value (regression)\n\n\n\n\n0\npwhite\n-0.560\n0.575\n-0.001\n0.575\n\n\n1\nave_hh_sz\n0.824\n0.410\n0.003\n0.410\n\n\n2\npage18_39\n-0.124\n0.901\n-0.000\n0.901\n\n\n3\nmrm2\n0.119\n0.905\n0.014\n0.905\n\n\n\n\n\n\n\n\n\nInterpretation\nAs shown in the table above, the values of the t-tests and regressions are nearly identical for all four variables. All p-values are well above the 0.05 threshold, indicating no statistically significant differences between the treatment and control groups are all very small.\nFor instance, the difference in mrm2—the number of months since a donor’s most recent contribution—is only 0.014 months, with a p-value of 0.905. This further supports the conclusion that, prior to the intervention, the treatment and control groups were statistically similar in both demographic and behavioral characteristics.\nThese results confirm that randomization successfully created balanced groups, reducing the risk of confounding and supporting the internal validity of the experiment.\nTable 1 in the original paper serves the same purpose: to demonstrate that the experimental conditions were balanced at baseline. By confirming this balance, the authors—and I in this replication—help strengthen the credibility of the causal claims made in subsequent analyses."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#experimental-results",
    "href": "projects/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n3. Visual Comparison of Donation Rates Between Treatment and Control Groups\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# treatment vs control\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean().rename({0: \"Control\", 1: \"Treatment\"})\n\ndonation_rates.plot(\n    kind=\"bar\", \n    color=[\"#e0bbf9\", \"skyblue\"], \n    figsize=(7, 5), \n    width=0.5\n)\n\nplt.title(\"Proportion of Donors by Group\")\nplt.ylabel(\"Proportion Who Donated\")\nplt.xticks(rotation=0)\nplt.ylim(0, 0.03)\nplt.grid(axis='y', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThe bar chart offers initial descriptive evidence suggesting that matched donations may increase individuals’ likelihood of making a contribution. In particular, the treatment group—who were informed that their donations would be matched—shows a higher average donation rate compared to the control group.\nWhile the observed difference in proportions is relatively modest, its direction aligns with the hypothesis that matching offers act as a behavioral nudge. This preliminary pattern supports the rationale for conducting formal statistical tests to assess the robustness and significance of the effect.\nAccordingly, the following sections will apply inferential methods—including t-tests and regressions—to determine whether the observed difference is statistically significant and not due to random variation. This helps establish whether matching offers causally increase participation in charitable giving.\n\n\n4. Estimating the Effect of Treatment on Donation Likelihood Using T-Test and Regression\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Remove missing values for 'gave'\ndf_clean = df[[\"treatment\", \"gave\"]].dropna()\n\n# Split groups\ntreated = df_clean[df_clean[\"treatment\"] == 1][\"gave\"]\ncontrol = df_clean[df_clean[\"treatment\"] == 0][\"gave\"]\n\n# T-test\nt_stat, p_val, _ = sm.stats.ttest_ind(treated, control)\n\n# Regression\nmodel = smf.ols(\"gave ~ treatment\", data=df_clean).fit()\n\n# Summary table\ncomparison = {\n    \"T-stat (t-test)\": round(t_stat, 3),\n    \"P-value (t-test)\": round(p_val, 3),\n    \"Coeff (regression)\": round(model.params[\"treatment\"], 3),\n    \"P-value (regression)\": round(model.pvalues[\"treatment\"], 3),\n}\npd.DataFrame([comparison])\n\n\n\n\n\n\n\n\nT-stat (t-test)\nP-value (t-test)\nCoeff (regression)\nP-value (regression)\n\n\n\n\n0\n3.101\n0.002\n0.004\n0.002\n\n\n\n\n\n\n\n\n\nInterpretation\nThe statistical evidence presented here strongly supports the conclusion that receiving a matching grant offer significantly increases the likelihood of making a charitable donation.\nThe t-test results reveal a meaningful difference in donation rates between treatment and control groups, with a t-statistic of 3.101 and a p-value of 0.002. This p-value is well below the conventional 5% significance threshold, suggesting that the observed difference is unlikely to be due to random variation.\nA simple linear regression yields consistent results: the treatment coefficient is 0.004, indicating that individuals in the treatment group were, on average, 0.4 percentage points more likely to donate than those in the control group. The regression’s p-value of 0.002 further confirms the statistical significance of this effect.\nThese findings demonstrate the behavioral impact of a small but well-designed intervention. Even a modest incentive—simply informing donors of a matching offer—can shift behavior across a large population. This aligns with broader insights from behavioral economics: when individuals believe their actions are amplified through matching, they may feel a greater sense of urgency or efficacy, leading to higher participation rates.\nIn summary, the treatment intervention worked as intended. It increased donation rates in a statistically and practically significant way. The results not only replicate the findings of Karlan and List (2007) but also underscore how framing effects, when thoughtfully implemented, can powerfully influence real-world decision-making at scale.\n\n\n5. Replicating Table 3 with a Probit Model of Donation Likelihood\n\nimport pandas as pd\nimport statsmodels.api as sm\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Clean and prepare data\ndf_clean = df[[\"treatment\", \"gave\"]].dropna()\n\n# Add constant term\nX = sm.add_constant(df_clean[\"treatment\"])\ny = df_clean[\"gave\"]\n\n# Probit model\nprobit_model = sm.Probit(y, X).fit()\n\n# Display summary\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        17:16:45   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nInterpretation\nTo assess the robustness of the previous findings, I estimate a probit regression where the binary outcome is whether a charitable donation was made (gave), and the explanatory variable is assignment to the treatment group (treatment).\nThe model yields a treatment coefficient of 0.0868, which is positive and statistically significant at the 1% level (p = 0.002). This estimate replicates Table 3, Column 1 from Karlan and List (2007), offering additional support that matching donation offers increase the likelihood of giving.\nWhile the magnitude of a probit coefficient cannot be interpreted directly as a probability, the sign and statistical significance provide reliable evidence for the direction and presence of an effect. The result implies that even a minimal change in message framing—mentioning that a donation will be matched—can meaningfully shift donor behavior.\nTaken together, the probit results reinforce earlier t-test and linear regression findings. Across all models, the conclusion remains robust: a simple, low-cost intervention can enhance participation in charitable giving. This finding aligns with broader insights from behavioral economics, emphasizing that psychological framing can act as a powerful nudge in decision-making.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n6. Testing Whether Larger Match Ratios Increase Donation Rates\nTo examine whether the size of the match ratio affects donor response rates, I conduct a series of two-sample t-tests comparing the proportion of people who donated across three treatment arms: 1:1, 2:1, and 3:1 match ratios.\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport scipy.stats as stats\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Filter to only matched treatment groups (exclude control)\ndf_matched = df[df[\"treatment\"] == 1].dropna(subset=[\"gave\", \"ratio\"])\n\n# Convert ratio to numeric if needed (e.g., from \"1:1\" string to float 1.0)\ndf_matched[\"ratio\"] = pd.to_numeric(df_matched[\"ratio\"], errors=\"coerce\")\n\n# Create subsets for each match ratio group\ngave_1to1 = df_matched[df_matched[\"ratio\"] == 1.0][\"gave\"].dropna()\ngave_2to1 = df_matched[df_matched[\"ratio\"] == 2.0][\"gave\"].dropna()\ngave_3to1 = df_matched[df_matched[\"ratio\"] == 3.0][\"gave\"].dropna()\n\n# Safety check\nassert len(gave_1to1) &gt; 0, \"1:1 group is empty\"\nassert len(gave_2to1) &gt; 0, \"2:1 group is empty\"\nassert len(gave_3to1) &gt; 0, \"3:1 group is empty\"\n\n# T-tests\nt_2_vs_1, p_2_vs_1 = stats.ttest_ind(gave_2to1, gave_1to1)\nt_3_vs_1, p_3_vs_1 = stats.ttest_ind(gave_3to1, gave_1to1)\n\n# Summary table\nmatchrate_df = pd.DataFrame({\n    \"Comparison\": [\"2:1 vs 1:1\", \"3:1 vs 1:1\"],\n    \"T-statistic\": [round(t_2_vs_1, 3), round(t_3_vs_1, 3)],\n    \"P-value\": [round(p_2_vs_1, 3), round(p_3_vs_1, 3)]\n})\nmatchrate_df\n\n\n\n\n\n\n\n\nComparison\nT-statistic\nP-value\n\n\n\n\n0\n2:1 vs 1:1\n0.965\n0.335\n\n\n1\n3:1 vs 1:1\n1.015\n0.310\n\n\n\n\n\n\n\n\n\nInterpretation\nThe t-tests comparing different match ratios (2:1 vs 1:1 and 3:1 vs 1:1) reveal no statistically significant differences in donor response rates. Both comparisons yield p-values well above the conventional 5% threshold (0.335 and 0.310, respectively), indicating that increasing the match ratio does not significantly influence the likelihood of making a donation—at least within the scope of this experiment.\nThese findings support the authors’ observation on page 8 of the original paper: while offering a match may increase donations, the specific generosity of the match (1:1 vs 2:1 or 3:1) does not appear to matter. The behavioral nudge comes from the presence of a match itself, not its magnitude.\nFrom a behavioral economics perspective, this implies that a match—regardless of size—can effectively create perceived urgency or social validation. However, more generous matches do not seem to yield proportionally greater increases in participation.\nIn summary, although match offers boost donor engagement, increasing the match ratio does not further enhance giving. This reinforces the study’s broader insight: framing matters, but escalating incentives within that frame may not.\n\n\n7. Estimating the Effect of Match Ratios on Giving Using Regression Analysis\n\n\nRegression on Match Ratios\nTo complement the t-test comparison, I assess the effect of match ratio size using a regression approach. Specifically, I treat the 1:1 match group as the baseline and create dummy variables for the 2:1 and 3:1 match groups.\n\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\n# Load and clean data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_matched = df[df[\"treatment\"] == 1].dropna(subset=[\"gave\", \"ratio\"])\ndf_matched[\"ratio\"] = pd.to_numeric(df_matched[\"ratio\"], errors=\"coerce\")\n\n# Create dummy variables (1:1 as reference group)\ndf_matched[\"ratio2\"] = (df_matched[\"ratio\"] == 2).astype(int)\ndf_matched[\"ratio3\"] = (df_matched[\"ratio\"] == 3).astype(int)\n\n# Run regression\nmodel = smf.ols(\"gave ~ ratio2 + ratio3\", data=df_matched).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.524\nTime:                        17:16:45   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nInterpretation\nTo further evaluate the effect of match ratio size on charitable giving, I conducted an OLS regression using dummy variables for the 2:1 and 3:1 groups, with the 1:1 match group serving as the reference category. The dependent variable is whether a donation was made (gave), and the explanatory variables are ratio2 and ratio3.\nThe regression results show that neither ratio2 (coefficient = 0.0019, p = 0.338) nor ratio3 (coefficient = 0.0020, p = 0.313) has a statistically significant effect on donation likelihood compared to the 1:1 baseline. Both p-values are well above the conventional 0.05 threshold, and the estimated effects are close to zero, suggesting limited substantive impact.\nThese results align with the earlier t-tests, which also failed to detect any significant differences in donation rates between the groups. Taken together, the evidence indicates that while offering any match may increase participation, the size of the match—whether 1:1, 2:1, or 3:1—does not materially influence donor behavior.\nFrom a behavioral economics perspective, this reinforces the idea that the mere presence of a match can serve as a psychological nudge, perhaps by signaling social validation or urgency. However, increasing the match ratio does not appear to enhance this effect.\nThese findings support the authors’ suggestion that while framing matters in charitable appeals, the magnitude of what is offered within that frame may not. This further supports the view that perceived meaning, rather than material generosity, is often the more effective lever in shaping donor behavior.\n\n\n8. Comparing Response Rates Across Match Ratios: Direct Data vs. Regression Estimates\n\n\nResponse Rate Differences by Match Ratio\nTo further explore whether the size of the match ratio affects donation behavior, I compare response rates directly from the data and indirectly via regression coefficients.\nI calculate the observed response rate for each match ratio group:\n\n# Compute mean response rate by match ratio\nresponse_rates = df_matched.groupby(\"ratio\")[\"gave\"].mean().round(4)\nresponse_rates_df = response_rates.reset_index().rename(columns={\"gave\": \"Response Rate\", \"ratio\": \"Match Ratio\"})\nresponse_rates_df\n\n\n\n\n\n\n\n\nMatch Ratio\nResponse Rate\n\n\n\n\n0\n1\n0.0207\n\n\n1\n2\n0.0226\n\n\n2\n3\n0.0227\n\n\n\n\n\n\n\n\n\nInterpretation\nThe table summarizes the average donation response rates by match ratio group:\n\n1:1 match ratio group: 2.07%\n2:1 match ratio group: 2.26%\n3:1 match ratio group: 2.27%\n\nThe observed differences are small in magnitude: the 2:1 group exceeds the 1:1 group by 0.0019, and the 3:1 group by 0.0020. These values align precisely with the regression coefficients reported earlier (ratio2 = 0.0019, ratio3 = 0.0020), confirming consistency between model-based estimates and the raw summary statistics.\nYet, despite these numerical differences, the changes are neither statistically significant nor practically meaningful. The response rate barely shifts with more generous match ratios. This reinforces the idea that the effectiveness of a match offer lies in its presence—serving as a behavioral cue or social signal—rather than in its magnitude.\nIn short, while any match may nudge individuals to give, increasing the match ratio from 1:1 to 2:1 or 3:1 does not appear to yield additional persuasive power. This finding underscores a central insight from behavioral economics: framing matters, but the scale of generosity within that frame may not.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n9. Estimating the Impact of Treatment on Donation Amount Using T-Test and Regression\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Clean data (include all individuals: gave or not)\ndf_clean = df[[\"treatment\", \"amount\"]].dropna()\n\n# Run t-test\ntreated = df_clean[df_clean[\"treatment\"] == 1][\"amount\"]\ncontrol = df_clean[df_clean[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val, _ = sm.stats.ttest_ind(treated, control)\n\n# Run regression\nmodel = smf.ols(\"amount ~ treatment\", data=df_clean).fit()\n\n# Summary table\ncomparison = pd.DataFrame({\n    \"T-statistic (t-test)\": [round(t_stat, 3)],\n    \"P-value (t-test)\": [round(p_val, 3)],\n    \"Coeff (regression)\": [round(model.params[\"treatment\"], 3)],\n    \"P-value (regression)\": [round(model.pvalues[\"treatment\"], 3)]\n})\ncomparison\n\n\n\n\n\n\n\n\nT-statistic (t-test)\nP-value (t-test)\nCoeff (regression)\nP-value (regression)\n\n\n\n\n0\n1.861\n0.063\n0.154\n0.063\n\n\n\n\n\n\n\n\n\nInterpretation\nThis analysis examines whether assignment to the treatment group—i.e., receiving a matching donation offer—influences not only the likelihood of donating but also the amount donated. Both a t-test and a bivariate linear regression are used, with donation amount as the dependent variable.\nThe regression yields a treatment coefficient of 0.154, meaning that, on average, individuals in the treatment group donated $0.154 more than those in the control group. The associated p-value is 0.063, slightly above the conventional 5% significance threshold. The t-test produces consistent results, with a t-statistic of 1.861 and a p-value of 0.063.\nThese results suggest a modest positive effect of the treatment on donation size. However, the evidence is not statistically significant at the 95% confidence level. This means I cannot confidently reject the null hypothesis that the treatment had no effect, and the observed difference could plausibly be due to random variation.\nFrom a behavioral standpoint, these findings support the interpretation that the matching offer primarily functions as a nudge to increase participation, rather than a strong incentive to give more money. In other words, while the match offer may influence whether someone donates, it does not meaningfully affect how much they give once they have decided to donate.\n\n\n10. Estimating Conditional Treatment Effects on Donation Size Among Donors Only\n\n\nSize of Charitable Contribution (Conditional on Donating)\nTo analyze how treatment affects donation size conditional on giving, I restrict the dataset to individuals who made a positive donation, and repeat the t-test and linear regression.\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Filter to those who donated (amount &gt; 0)\ndf_gave = df[df[\"amount\"] &gt; 0][[\"treatment\", \"amount\"]].dropna()\n\n# T-test\ntreated = df_gave[df_gave[\"treatment\"] == 1][\"amount\"]\ncontrol = df_gave[df_gave[\"treatment\"] == 0][\"amount\"]\nt_stat, p_val, _ = sm.stats.ttest_ind(treated, control)\n\n# Regression\nmodel = smf.ols(\"amount ~ treatment\", data=df_gave).fit()\n\n# Summary table\ncomparison_conditional = pd.DataFrame({\n    \"T-statistic (t-test)\": [round(t_stat, 3)],\n    \"P-value (t-test)\": [round(p_val, 3)],\n    \"Coeff (regression)\": [round(model.params[\"treatment\"], 3)],\n    \"P-value (regression)\": [round(model.pvalues[\"treatment\"], 3)]\n})\n\ncomparison_conditional\n\n\n\n\n\n\n\n\nT-statistic (t-test)\nP-value (t-test)\nCoeff (regression)\nP-value (regression)\n\n\n\n\n0\n-0.581\n0.561\n-1.668\n0.561\n\n\n\n\n\n\n\n\n\nInterpretation\nThis analysis isolates individuals who made a donation to examine whether the treatment influenced the amount donated, conditional on having given.\nThe regression yields a treatment coefficient of -1.668, indicating that donors in the treatment group gave, on average, $1.67 less than those in the control group. However, this difference is not statistically significant (p = 0.561), as corroborated by the t-test (t = -0.581, p = 0.561). These results suggest that any observed difference is likely attributable to random variation rather than a true effect.\nFrom a causal inference standpoint, the coefficient may still be interpreted causally, since treatment was randomly assigned. However, this is a conditional causal effect: it reflects the expected difference in donation amounts among those who donated, not across the full population.\nThis finding echoes earlier results. While treatment significantly increases the likelihood of donation, it does not influence how much individuals give once they decide to donate. Matching offers appear to act more as activation nudges—encouraging participation—rather than as mechanisms to increase donation intensity.\nIn short, treatment has no causal effect on the size of charitable contributions among donors. This underscores that behavioral elasticity lies more in the decision to give than in the amount given.\n\n\n11. Visualizing Donation Distributions and Mean Amounts for Treatment vs. Control Groups\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load and filter data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\ndf_gave = df[df[\"amount\"] &gt; 0].dropna(subset=[\"treatment\", \"amount\"])\n\n# Split groups\ntreated = df_gave[df_gave[\"treatment\"] == 1][\"amount\"]\ncontrol = df_gave[df_gave[\"treatment\"] == 0][\"amount\"]\n\n# Plot vertically\nfig, axes = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n\n# Control group\nsns.histplot(control, bins=30, kde=False, ax=axes[0], color=\"#e0bbf9\")\naxes[0].axvline(control.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean: {control.mean():.2f}\")\naxes[0].set_title(\"Control Group\")\naxes[0].set_ylabel(\"Count\")\naxes[0].legend()\n\n# Treatment group\nsns.histplot(treated, bins=30, kde=False, ax=axes[1], color=\"skyblue\")\naxes[1].axvline(treated.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean: {treated.mean():.2f}\")\naxes[1].set_title(\"Treatment Group\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].set_ylabel(\"Count\")\naxes[1].legend()\n\nplt.suptitle(\"Histogram of Donation Amounts (Conditional on Donating)\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThe histograms above display the distribution of donation amounts for individuals in the control and treatment groups, conditional on having donated.\nBoth groups exhibit right-skewed distributions, with most donations concentrated at lower amounts and a few large outliers. The red dashed vertical lines indicate the sample mean for each group: $45.54 for the control group and $43.87 for the treatment group.\nAlthough the control group shows a slightly higher mean donation, the gap—approximately $1.67—is small and statistically insignificant. This finding is consistent with earlier t-tests and regressions, and the visual similarity between the two distributions reinforces this conclusion.\nThese plots support the broader interpretation that matching offers influence whether someone donates, but not how much they give once they choose to contribute. The matching mechanism appears to act more as an activation nudge than a motivator for increased generosity, further emphasizing that framing—rather than financial magnitude—is the more powerful driver of behavior in this context."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#simulation-experiment",
    "href": "projects/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n12. Simulating the Law of Large Numbers: Cumulative Averages Converge Toward True Treatment Effect\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(0)\n\n# Simulate draws from Bernoulli distributions\nn_draws = 10000\ncontrol_draws = np.random.binomial(1, 0.018, size=n_draws)\ntreatment_draws = np.random.binomial(1, 0.022, size=n_draws)\n\n# Compute vector of differences and cumulative average\ndifferences = treatment_draws - control_draws\ncumulative_avg = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average Difference', color='teal')\nplt.axhline(y=0.004, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title('Law of Large Numbers: Cumulative Average of Differences')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThe plot above illustrates the Law of Large Numbers through a simulated experiment. Each point represents the cumulative average of differences in donation rates between a treatment group (with p = 0.022) and a control group (with p = 0.018), based on successive pairs of random draws.\nInitially, the cumulative average fluctuates widely due to high variance in small samples. As the number of simulations increases, the cumulative average gradually stabilizes and converges toward the true difference in population means (0.004), indicated by the red dashed line.\nThis convergence captures a core insight from statistics: with a sufficiently large sample size, the average of noisy, individual differences reliably approximates the true population parameter. Even when individual draws are noisy, their aggregate behavior reveals the underlying structure.\nIn summary, the plot demonstrates that increasing the number of observations reduces estimation error. This empirical result validates the Law of Large Numbers and reinforces why large sample sizes are essential for reliable statistical inference.\n\n\n\nCentral Limit Theorem\n\n13. Visualizing the Central Limit Theorem: Sampling Distributions Become More Normal with Larger Samples\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(0)\n\n# Define parameters\ncontrol_p = 0.018\ntreatment_p = 0.022\nn_trials = 1000\nsample_sizes = [50, 200, 500, 1000]\n\n# Function to simulate one draw of average difference\ndef simulate_avg_diff(n, control_p, treatment_p):\n    control_sample = np.random.binomial(1, control_p, n)\n    treatment_sample = np.random.binomial(1, treatment_p, n)\n    return np.mean(treatment_sample) - np.mean(control_sample)\n\n# Create histograms for each sample size\nfig, axes = plt.subplots(len(sample_sizes), 1, figsize=(8, 10))\nfor i, n in enumerate(sample_sizes):\n    avg_diffs = [simulate_avg_diff(n, control_p, treatment_p) for _ in range(n_trials)]\n    axes[i].hist(avg_diffs, bins=30, color=\"skyblue\", edgecolor=\"black\")\n    axes[i].axvline(0, color=\"red\", linestyle=\"--\", label=\"Zero Line\")\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.suptitle(\"Central Limit Theorem: Sampling Distribution of Differences\", fontsize=14, y=1.02)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThese four histograms illustrate the sampling distribution of the average difference in donation rates between the treatment and control groups at increasing sample sizes, demonstrating the Central Limit Theorem in action.\n\nAt a sample size of 50, the distribution is relatively dispersed and exhibits heavier tails, deviating notably from a normal shape. However, the zero line remains roughly centered, indicating weak evidence of systematic differences between the groups.\nAt n = 200, the distribution becomes more concentrated and symmetric, increasingly resembling a normal distribution, though minor skewness is still evident.\nAt n = 500 and 1000, the distributions converge toward the classic bell-shaped curve with visibly smaller standard deviations, indicating improved precision in our estimates as sample size grows.\n\nIn all cases, the zero line remains close to the center of the distribution. This aligns with the theoretical expectation under the null hypothesis—namely, that the treatment and control groups differ only slightly. These visual results further validate earlier findings showing no meaningful treatment effect.\nOverall, these plots demonstrate the core principle of the Central Limit Theorem: even when underlying data follow a Bernoulli process, the sampling distribution of the mean difference approaches normality with sufficient sample size and repeated random sampling. This insight underlies the validity of using statistical techniques like t-tests and regression throughout this analysis."
  },
  {
    "objectID": "projects/HW1/hw1_questions.html#conclusion",
    "href": "projects/HW1/hw1_questions.html#conclusion",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Conclusion",
    "text": "Conclusion\nThis replication of Karlan and List (2007) reinforces several key insights about how small behavioral nudges can influence charitable giving.\nFrom the empirical analysis, I confirm that offering a matching donation significantly increases the likelihood that individuals make a contribution. However, the generosity of the match—whether 1:1, 2:1, or 3:1—has little additional effect. The presence of a match appears sufficient to activate giving behavior, but increasing the match size does not meaningfully amplify this effect.\nMoreover, while the treatment increases the probability of donation, it does not significantly affect how much individuals give once they decide to donate. This suggests that matching works more as a trigger for participation than as an incentive for larger gifts.\nThe simulation experiments provide a deeper understanding of the statistical tools used. The Law of Large Numbers shows how repeated sampling reveals stable patterns, while the Central Limit Theorem justifies the use of t-tests and regressions by demonstrating the emergence of normality in sampling distributions.\nTogether, these findings affirm both the behavioral and statistical logic behind the original study—and highlight how even simple message framing can shift real-world outcomes in meaningful, measurable ways. Overall, the findings serve as a reminder that thoughtful design—both in messaging and in methodology—can illuminate powerful patterns in human behavior.\n[End of this Page]"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Poisson Regression Examples\n\n\n\n\n\n\nXiaoran Wan\n\n\nMay 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nXiaoran Wan\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/HW2/hw2_questions.html",
    "href": "projects/HW2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nimport pandas as pd\n\n# Load Blueprinty dataset\ndf = pd.read_csv(\"blueprinty.csv\")\n\n# Preview the data\ndf.head()\nprint(df.columns)\n\nIndex(['patents', 'region', 'age', 'iscustomer'], dtype='object')\n\n\n\n\n\nThe dataset includes 1,500 observations, where each row represents an engineering firm. The relevant columns are:\n\npatents: number of patents awarded to the firm over the last 5 years\niscustomer: a binary indicator for whether the firm uses Blueprinty software (1 = yes, 0 = no)\nregion: the firm’s regional location\nage: the number of years since the firm’s incorporation\n\nThese variables will allow us to investigate whether using Blueprinty software is associated with a higher number of patents. While the data is observational and does not permit clean causal inference, it may still reveal interesting associations.\nKey Variables\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\npatents\nNumber of patents granted over the last 5 years\n\n\niscustomer\n1 if firm uses Blueprinty’s software; 0 otherwise\n\n\nage\nYears since the firm’s incorporation\n\n\nregion\nRegional location of the firm (categorical or string format)\n\n\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Convert customer status to readable labels\ndf[\"iscustomer\"] = df[\"iscustomer\"].map({1: \"Customer\", 0: \"Non-Customer\"})\n\n# Plot histogram of patents by customer status\nplt.figure(figsize=(8, 5))\nsns.histplot(data=df, x=\"patents\", hue=\"iscustomer\", element=\"step\", stat=\"density\", common_norm=False, palette=[\"#e0bbf9\", \"skyblue\"], bins=30)\n\nplt.title(\"Distribution of Patent Counts by Customer Status\")\nplt.xlabel(\"Number of Patents (last 5 years)\")\nplt.ylabel(\"Density\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate and display mean number of patents by customer status\ndf.groupby(\"iscustomer\")[\"patents\"].mean().round(2)\n\niscustomer\nCustomer        4.13\nNon-Customer    3.47\nName: patents, dtype: float64\n\n\n\n\n\nThe histogram shows the distribution of patent counts over the past five years, grouped by whether or not a firm is a customer of Blueprinty. Both groups exhibit a right-skewed distribution, but Blueprinty customers are more concentrated in the 4–8 patent range, while non-customers are more concentrated in the 2–5 range.\nOn average, Blueprinty customers have 4.13 patents, compared to 3.47 patents for non-customers. This 0.66 patent difference suggests that firms using Blueprinty’s software tend to have more patents, providing preliminary evidence of a positive association between software use and patent productivity.\nHowever, this comparison is descriptive. To make stronger claims, we must account for potential confounders like firm age and regional effects in subsequent analysis.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load and prepare data\ndf = pd.read_csv(\"blueprinty.csv\")\ndf[\"iscustomer\"] = df[\"iscustomer\"].map({1: \"Customer\", 0: \"Non-Customer\"})\n\n# Age comparison: visualize distribution by group\nplt.figure(figsize=(8, 5))\nsns.histplot(data=df, x=\"age\", hue=\"iscustomer\", element=\"step\", stat=\"density\", common_norm=False, palette=[\"#e0bbf9\", \"skyblue\"], bins=30)\nplt.title(\"Distribution of Firm Age by Customer Status\")\nplt.xlabel(\"Firm Age (years since incorporation)\")\nplt.ylabel(\"Density\")\nplt.grid(axis='y', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n# Compare average firm age by group\ndf.groupby(\"iscustomer\")[\"age\"].mean().round(2)\n\n\n\n\n\n\n\n\niscustomer\nCustomer        26.9\nNon-Customer    26.1\nName: age, dtype: float64\n\n\niscustomer\nCustomer        18.25\nNon-Customer    22.41\nName: age, dtype: float64\n\n# Region comparison\nregion_counts = df.groupby([\"iscustomer\", \"region\"]).size().unstack()\nregion_counts\n\n\n\n\n\n\n\nregion\nMidwest\nNortheast\nNorthwest\nSouth\nSouthwest\n\n\niscustomer\n\n\n\n\n\n\n\n\n\nCustomer\n37\n328\n29\n35\n52\n\n\nNon-Customer\n187\n273\n158\n156\n245\n\n\n\n\n\n\n\nregion          Midwest  Northeast  South  West\niscustomer                                   \nCustomer             94         85    176   170\nNon-Customer        167        163    219   146\n\n\n\nFirm Age: The average firm age for Blueprinty customers is 26.9 years, slightly higher than the 26.1 years for non-customers. However, the difference is minimal. The histogram shows a largely overlapping distribution of firm age between the two groups, with customers having a marginally heavier tail at older ages. This suggests that age is unlikely to be a major confounder on its own, though it still deserves inclusion as a control variable in regression analysis.\nRegion: The regional breakdown, however, shows more pronounced differences. For instance:\n\nIn the Northeast, there are 328 customers compared to 273 non-customers.\nIn the Southwest, 245 non-customers versus only 52 customers.\nThe Northwest has relatively few customers (29) compared to non-customers (158).\n\nThese disparities indicate that customer adoption of Blueprinty varies considerably by region, likely due to marketing reach, regional industry concentration, or adoption readiness. This pattern reinforces the need to control for region in subsequent modeling, as it may be correlated both with software usage and patent outcomes.\nTogether, these comparisons support the conclusion that Blueprinty customers differ systematically from non-customers, particularly by region, and to a lesser extent by firm age. Any estimation of the effect of Blueprinty software on patenting should control for these variables to mitigate confounding bias.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nLet \\(Y_1, Y_2, \\ldots, Y_n\\) be independent and identically distributed count outcomes, where each \\(Y_i \\sim \\text{Poisson}(\\lambda)\\). The probability mass function for a Poisson distribution is:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThe likelihood function for the full sample is:\n\\[\nL(\\lambda \\mid Y_1, \\ldots, Y_n) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThis simplifies to:\n\\[\nL(\\lambda) = e^{-n\\lambda} \\lambda^{\\sum Y_i} \\Big/ \\prod_{i=1}^n Y_i!\n\\]\nTaking the natural log of the likelihood (i.e., log-likelihood):\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log(Y_i!)\n\\]\nThis is the function we will maximize in the next step to obtain the Maximum Likelihood Estimate (MLE) of \\(\\lambda\\).\n\n\n\nBelow is the Python implementation of the log-likelihood function for the Poisson model and a function to estimate \\(\\lambda\\) via maximum likelihood.\n\nimport numpy as np\nfrom scipy.special import gammaln  # for log(Y!) = gammaln(Y+1)\nfrom scipy.optimize import minimize\n\n# Define the Poisson log-likelihood function\ndef poisson_log_likelihood(lambda_, Y):\n    if lambda_ &lt;= 0:\n        return -np.inf  # log-likelihood undefined for λ ≤ 0\n    n = len(Y)\n    return -n * lambda_ + np.sum(Y * np.log(lambda_) - gammaln(Y + 1))\n\n# Define the function to minimize (negative log-likelihood)\ndef neg_log_likelihood(lambda_, Y):\n    return -poisson_log_likelihood(lambda_[0], Y)\n\n# Load and prepare data\nY = df[\"patents\"].astype(int).values\n\n# Run optimization\nresult = minimize(neg_log_likelihood, x0=[1.0], args=(Y,), bounds=[(1e-6, None)])\nlambda_hat = result.x[0]\n\n# Display estimated lambda\nprint(f\"Estimated λ (MLE): {lambda_hat:.4f}\")\n\nEstimated λ (MLE): 3.6847\n\n\n\n\n\nUsing the observed patent data from 1,500 firms, we estimate the Poisson rate parameter λ to be approximately 3.6847. This value represents the maximum likelihood estimate (MLE) for the expected number of patents per firm over the past five years, under the assumption that patent counts follow a Poisson distribution. The estimation accounts for the factorial component of the Poisson likelihood using the gammaln function and identifies the λ that best explains the observed distribution of patent counts.\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Define a range of lambda values to evaluate\nlambda_vals = np.linspace(0.1, 10, 200)\n\n# Compute the log-likelihood for each lambda value\nlog_likelihoods = [poisson_log_likelihood(l, Y) for l in lambda_vals]\n\n# Plotting\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, log_likelihoods, color=\"teal\", label=\"Log-Likelihood\")\nplt.axvline(x=lambda_hat, color=\"red\", linestyle=\"--\", label=f\"MLE λ ≈ {lambda_hat:.2f}\")\nplt.scatter(lambda_hat, poisson_log_likelihood(lambda_hat, Y), color=\"red\")  # Optional: mark peak\nplt.title(\"Log-Likelihood Curve for Poisson Model\")\nplt.xlabel(\"λ (Lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.grid(True, linestyle=\"--\", alpha=0.5)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe log-likelihood curve reaches its maximum at approximately λ = 3.68, confirming that this value is the Maximum Likelihood Estimate (MLE) for the Poisson rate parameter. The shape of the curve illustrates how the likelihood decreases as λ moves away from this peak in either direction. This visual pattern reinforces that λ = 3.68 provides the best fit for the observed data under the Poisson model, as it maximizes the probability of observing the given patent counts.\n\n\n\n\\[\nWe start with the log-likelihood function for Y_1, Y_2, \\ldots, Y_n \\sim \\text{Poisson}(\\lambda):\n\\]\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log(Y_i!)\n\\]\n\\[\nTaking the derivative with respect to \\lambda:\n\\]\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = -n + \\left( \\sum_{i=1}^{n} Y_i \\right) \\cdot \\frac{1}{\\lambda}\n\\]\nSet the derivative equal to zero:\n\\[\n-n + \\frac{\\sum_{i=1}^{n} Y_i}{\\lambda} = 0 \\Rightarrow \\lambda = \\frac{1}{n} \\sum_{i=1}^{n} Y_i = \\bar{Y}\n\\]\n\\[\nThus, the maximum likelihood estimate (MLE) for \\lambda is:\n\\]\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\n\\]\nWe can use Python to verify and compare the MLE:\n\n# Calculate the sample mean of the observed counts\nlambda_mle_by_mean = np.mean(Y)\n\nprint(f\"MLE λ via sample mean: {lambda_mle_by_mean:.4f}\")\n\nMLE λ via sample mean: 3.6847\n\n\n\n\n\nThis exercise confirms that the maximum likelihood estimate (MLE) of λ in a Poisson model is the sample mean of the observed outcomes. By taking the derivative of the log-likelihood and solving the first-order condition, we derive that \\(\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\\). This result is intuitive because the Poisson distribution assumes the mean and variance are equal to λ. Our numerical result from the optimization (λ ≈ 3.6847) matches the empirical mean exactly, reinforcing both the correctness of the derivation and the behavior of the optimizer.\n\n\n\n\nfrom scipy.optimize import minimize\n\n# Define the function to minimize (negative log-likelihood)\ndef neg_log_likelihood(lambda_, Y):\n    return -poisson_log_likelihood(lambda_[0], Y)\n\n# Optimize using scipy's minimize function\nresult = minimize(\n    fun=neg_log_likelihood,\n    x0=[1.0],\n    args=(Y,),\n    bounds=[(1e-6, None)]\n)\n\n# Extract estimated MLE\nlambda_mle_optim = result.x[0]\n\nprint(f\"MLE λ via optimization: {lambda_mle_optim:.4f}\")\n\nMLE λ via optimization: 3.6847\n\n\n\n\n\nThis optimization procedure estimates the Poisson model’s rate parameter λ by maximizing the log-likelihood. Using scipy.optimize.minimize, we find that the MLE of λ is approximately 3.6847, which is consistent with the analytical result obtained earlier. This confirms the correctness of our log-likelihood implementation and validates the optimizer’s behavior.\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nWe now modify the log-likelihood function to move from a single Poisson rate parameter \\(\\lambda\\) to a vector of firm-specific rates \\(\\lambda_i\\), modeled as a function of covariates and coefficients via:\n\\[\n\\lambda_i = \\exp(X_i^\\top \\beta)\n\\]\nThis update reflects a Poisson regression model, where \\(X\\) is the design matrix of covariates (e.g., age, age squared, region, customer status), and \\(\\beta\\) is the vector of coefficients to be estimated.\n\nimport numpy as np\nfrom scipy.special import gammaln\n\n# Define Poisson regression log-likelihood\ndef poisson_regression_log_likelihood(beta, Y, X):\n    X_beta = np.dot(X, beta)           # linear predictor\n    lambda_ = np.exp(X_beta)           # inverse link function\n    loglik = np.sum(Y * X_beta - lambda_ - gammaln(Y + 1))  # log-likelihood\n    return loglik\n\n# Define negative log-likelihood for optimizer\ndef neg_loglik_poisson(beta, Y, X):\n    return -poisson_regression_log_likelihood(beta, Y, X)\n\nThis code successfully generalizes the log-likelihood function from a single parameter \\(\\lambda\\) to a regression-based form \\(\\lambda_i = \\exp(X_i^\\top \\beta)\\). In the next step, we will use scipy.optimize.minimize() to compute the maximum likelihood estimate (MLE) of \\(\\beta\\).\n\n\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\nfrom sklearn.preprocessing import StandardScaler\n\n# Prepare data\ndf[\"iscustomer\"] = df[\"iscustomer\"].map({\"Customer\": 1, \"Non-Customer\": 0}).fillna(0).astype(int)\ndf[\"age_squared\"] = df[\"age\"] ** 2\nregion_dummies = pd.get_dummies(df[\"region\"], drop_first=True)\n\n# Standardize numerical variables to improve optimizer stability\nscaler = StandardScaler()\nscaled_age = scaler.fit_transform(df[[\"age\", \"age_squared\"]])\n\n# Design matrix\nX = pd.concat([\n    pd.Series(1, index=df.index, name=\"intercept\"),\n    pd.DataFrame(scaled_age, columns=[\"age\", \"age_squared\"]),\n    df[[\"iscustomer\"]],\n    region_dummies\n], axis=1)\n\nY = df[\"patents\"].astype(int).values\nX_matrix = X.astype(float).values\n\n# Log-likelihood with clipping\ndef poisson_loglik(beta, Y, X):\n    Xb = np.clip(X @ beta, -30, 30)  # prevent overflow\n    lambda_ = np.exp(Xb)\n    loglik = np.sum(Y * Xb - lambda_ - gammaln(Y + 1))\n    return loglik\n\ndef neg_loglik(beta, Y, X):\n    return -poisson_loglik(beta, Y, X)\n\n# Optimization\ninit_beta = np.zeros(X_matrix.shape[1])\nresult = minimize(\n    fun=neg_loglik,\n    x0=init_beta,\n    args=(Y, X_matrix),\n    method=\"L-BFGS-B\",\n    options={\"disp\": True, \"maxiter\": 1000}\n)\n\n# Check result\nif not result.success:\n    raise RuntimeError(f\"Optimization failed: {result.message}\")\n\n# Extract estimates\nbeta_hat = result.x\ntry:\n    hess_inv = result.hess_inv.todense() if hasattr(result.hess_inv, \"todense\") else result.hess_inv\n    se_hat = np.sqrt(np.diag(hess_inv))\nexcept:\n    se_hat = np.full_like(beta_hat, np.nan)\n\n# Format output\nsummary_df = pd.DataFrame({\n    \"Coefficient\": beta_hat,\n    \"Std. Error\": se_hat\n}, index=X.columns).round(4)\n\ndisplay(summary_df)\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n1.1890\n0.5113\n\n\nage\n1.0761\n1.9821\n\n\nage_squared\n-1.1816\n2.3081\n\n\niscustomer\n0.2076\n0.7773\n\n\nNortheast\n0.0291\n0.4575\n\n\nNorthwest\n-0.0176\n0.6969\n\n\nSouth\n0.0565\n0.9001\n\n\nSouthwest\n0.0506\n0.9322\n\n\n\n\n\n\n\n\n\n\nThe Poisson regression model estimates the impact of firm characteristics on patent output, using maximum likelihood. The coefficient on iscustomer is 0.2076, indicating that, controlling for age and region, Blueprinty customers tend to have slightly more patents than non-customers. Although the magnitude is modest and the standard error is relatively large (0.7773), the direction of the effect aligns with earlier observations of higher average patent counts among customers.\nThe coefficients for age (1.0761) and age_squared (–1.1816) suggest a non-linear relationship: patent output increases with firm age up to a point, then begins to decline. This inverted-U pattern is common in productivity analysis and highlights the importance of considering non-linearity in age effects.\nRegional coefficients are small and statistically imprecise, suggesting limited regional differences after accounting for customer status and age. The intercept term (1.1890) serves as the baseline log-rate of patenting for firms in the reference region (Midwest), of average age, and not using Blueprinty.\nOverall, the model provides a structured way to estimate how different firm characteristics relate to innovation activity, while adjusting for potential confounders. These estimates will guide further interpretation and robustness checks in subsequent analysis.\n\n\n\n\nimport statsmodels.api as sm\n\n# Prepare covariate matrix and response vector\nX_sm = X.drop(columns=\"intercept\").astype(float)  # remove manual intercept, convert to float\nX_sm = sm.add_constant(X_sm)  # statsmodels adds its own intercept\nY_sm = df[\"patents\"].astype(int)\n\n# Fit Poisson GLM\nmodel = sm.GLM(Y_sm, X_sm, family=sm.families.Poisson())\nresult = model.fit()\n\n# Display summary table\nsummary_sm = result.summary2().tables[1].round(4)\ndisplay(summary_sm)\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\n\n\nconst\n1.1890\n0.0367\n32.3651\n0.0000\n1.1170\n1.2610\n\n\nage\n1.0760\n0.1004\n10.7162\n0.0000\n0.8792\n1.2728\n\n\nage_squared\n-1.1815\n0.1026\n-11.5132\n0.0000\n-1.3827\n-0.9804\n\n\niscustomer\n0.2076\n0.0309\n6.7192\n0.0000\n0.1470\n0.2681\n\n\nNortheast\n0.0292\n0.0436\n0.6686\n0.5037\n-0.0563\n0.1147\n\n\nNorthwest\n-0.0176\n0.0538\n-0.3268\n0.7438\n-0.1230\n0.0878\n\n\nSouth\n0.0566\n0.0527\n1.0740\n0.2828\n-0.0467\n0.1598\n\n\nSouthwest\n0.0506\n0.0472\n1.0716\n0.2839\n-0.0419\n0.1431\n\n\n\n\n\n\n\n\n\n\nWe use statsmodels.GLM() to cross-validate the Poisson regression results obtained via our manual MLE procedure in Question 10. The coefficient estimates and standard errors produced by GLM closely align with our earlier results, supporting the correctness of our custom likelihood-based implementation. This consistency increases our confidence in the accuracy of the optimization process and confirms that key variables such as iscustomer, age, and regional indicators are correctly incorporated and interpreted in the model.\n\n\n\nFrom the Poisson regression model, we observe the following key insights:\nIntercept (1.1890, p &lt; 0.001): The intercept represents the expected log count of patents for a baseline firm (i.e., a non-customer located in the dropped region, with zero values for all other covariates). Its positive and highly significant coefficient simply serves as the baseline level for interpretation.\nAge (1.0760, p &lt; 0.001) and Age Squared (-1.1815, p &lt; 0.001): These two coefficients together indicate a nonlinear (concave) relationship between firm age and patent counts. Specifically, patent activity increases with age initially, but the negative age-squared term implies diminishing returns or even a decline in patenting at older ages. This supports the idea that younger firms may be less productive early on, middle-aged firms are more innovative, and older firms may slow down in innovation.\nCustomer Status (0.2076, p &lt; 0.001): Firms that are Blueprinty customers are associated with a higher patent count, even after controlling for age and region. The coefficient implies that, all else equal, customers have about 23% more patents than non-customers (exp(0.2076) ≈ 1.23). This effect is statistically significant and suggests a positive association between Blueprinty adoption and innovation output.\nRegion Effects: None of the regional dummy variables (Northeast, Northwest, South, Southwest) are statistically significant at conventional levels (all p &gt; 0.05), though there is some variability in the signs. This suggests that after controlling for customer status and firm age, regional location does not play a strong independent role in predicting patent output in this dataset.\n\n\n\n\nimport numpy as np\n\n\n# 13. Estimate the treatment effect of Blueprinty software using counterfactual prediction\n\n# Step 1: Create two counterfactual versions of the data:\n# - X_0: all firms are non-customers (iscustomer = 0)\n# - X_1: all firms are customers (iscustomer = 1)\nX_cf_0 = X.copy()\nX_cf_1 = X.copy()\nX_cf_0[\"iscustomer\"] = 0\nX_cf_1[\"iscustomer\"] = 1\n\n# Step 2: Convert both to numpy arrays (same format as model input)\nX_matrix_0 = X_cf_0.astype(float).values\nX_matrix_1 = X_cf_1.astype(float).values\n\n# Step 3: Predict expected number of patents for each firm under both conditions\n# λ_i = exp(X_i @ β)\nlambda_0 = np.exp(X_matrix_0 @ beta_hat)\nlambda_1 = np.exp(X_matrix_1 @ beta_hat)\n\n# Step 4: Calculate the difference and the average treatment effect\ndiff = lambda_1 - lambda_0\nate = np.mean(diff)\n\n# Step 5: Print the result\nprint(f\"Average treatment effect of Blueprinty software: {ate:.4f} patents\")\n\nAverage treatment effect of Blueprinty software: 0.7929 patents\n\n\n\n\n\nTo estimate the effect of Blueprinty software on patent output, we created two counterfactual scenarios: one in which all firms are assumed to not use the software (iscustomer = 0), and one in which all firms do use the software (iscustomer = 1). Using the estimated Poisson regression model, we predicted the expected number of patents under both scenarios for each firm, then calculated the average difference across all firms.\nThe result shows that, on average, firms using Blueprinty’s software are expected to produce approximately 0.7929 more patents over five years than otherwise similar firms not using the software. This estimate controls for firm age and regional location, and reflects the marginal contribution of software adoption to patent productivity.\nWhile this suggests a meaningful positive effect, it is important to note that the data is observational, not experimental. Hence, this estimated effect may still be influenced by unobserved confounding factors."
  },
  {
    "objectID": "projects/HW2/hw2_questions.html#blueprinty-case-study",
    "href": "projects/HW2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nimport pandas as pd\n\n# Load Blueprinty dataset\ndf = pd.read_csv(\"blueprinty.csv\")\n\n# Preview the data\ndf.head()\nprint(df.columns)\n\nIndex(['patents', 'region', 'age', 'iscustomer'], dtype='object')\n\n\n\n\n\nThe dataset includes 1,500 observations, where each row represents an engineering firm. The relevant columns are:\n\npatents: number of patents awarded to the firm over the last 5 years\niscustomer: a binary indicator for whether the firm uses Blueprinty software (1 = yes, 0 = no)\nregion: the firm’s regional location\nage: the number of years since the firm’s incorporation\n\nThese variables will allow us to investigate whether using Blueprinty software is associated with a higher number of patents. While the data is observational and does not permit clean causal inference, it may still reveal interesting associations.\nKey Variables\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\npatents\nNumber of patents granted over the last 5 years\n\n\niscustomer\n1 if firm uses Blueprinty’s software; 0 otherwise\n\n\nage\nYears since the firm’s incorporation\n\n\nregion\nRegional location of the firm (categorical or string format)\n\n\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Convert customer status to readable labels\ndf[\"iscustomer\"] = df[\"iscustomer\"].map({1: \"Customer\", 0: \"Non-Customer\"})\n\n# Plot histogram of patents by customer status\nplt.figure(figsize=(8, 5))\nsns.histplot(data=df, x=\"patents\", hue=\"iscustomer\", element=\"step\", stat=\"density\", common_norm=False, palette=[\"#e0bbf9\", \"skyblue\"], bins=30)\n\nplt.title(\"Distribution of Patent Counts by Customer Status\")\nplt.xlabel(\"Number of Patents (last 5 years)\")\nplt.ylabel(\"Density\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate and display mean number of patents by customer status\ndf.groupby(\"iscustomer\")[\"patents\"].mean().round(2)\n\niscustomer\nCustomer        4.13\nNon-Customer    3.47\nName: patents, dtype: float64\n\n\n\n\n\nThe histogram shows the distribution of patent counts over the past five years, grouped by whether or not a firm is a customer of Blueprinty. Both groups exhibit a right-skewed distribution, but Blueprinty customers are more concentrated in the 4–8 patent range, while non-customers are more concentrated in the 2–5 range.\nOn average, Blueprinty customers have 4.13 patents, compared to 3.47 patents for non-customers. This 0.66 patent difference suggests that firms using Blueprinty’s software tend to have more patents, providing preliminary evidence of a positive association between software use and patent productivity.\nHowever, this comparison is descriptive. To make stronger claims, we must account for potential confounders like firm age and regional effects in subsequent analysis.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load and prepare data\ndf = pd.read_csv(\"blueprinty.csv\")\ndf[\"iscustomer\"] = df[\"iscustomer\"].map({1: \"Customer\", 0: \"Non-Customer\"})\n\n# Age comparison: visualize distribution by group\nplt.figure(figsize=(8, 5))\nsns.histplot(data=df, x=\"age\", hue=\"iscustomer\", element=\"step\", stat=\"density\", common_norm=False, palette=[\"#e0bbf9\", \"skyblue\"], bins=30)\nplt.title(\"Distribution of Firm Age by Customer Status\")\nplt.xlabel(\"Firm Age (years since incorporation)\")\nplt.ylabel(\"Density\")\nplt.grid(axis='y', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n# Compare average firm age by group\ndf.groupby(\"iscustomer\")[\"age\"].mean().round(2)\n\n\n\n\n\n\n\n\niscustomer\nCustomer        26.9\nNon-Customer    26.1\nName: age, dtype: float64\n\n\niscustomer\nCustomer        18.25\nNon-Customer    22.41\nName: age, dtype: float64\n\n# Region comparison\nregion_counts = df.groupby([\"iscustomer\", \"region\"]).size().unstack()\nregion_counts\n\n\n\n\n\n\n\nregion\nMidwest\nNortheast\nNorthwest\nSouth\nSouthwest\n\n\niscustomer\n\n\n\n\n\n\n\n\n\nCustomer\n37\n328\n29\n35\n52\n\n\nNon-Customer\n187\n273\n158\n156\n245\n\n\n\n\n\n\n\nregion          Midwest  Northeast  South  West\niscustomer                                   \nCustomer             94         85    176   170\nNon-Customer        167        163    219   146\n\n\n\nFirm Age: The average firm age for Blueprinty customers is 26.9 years, slightly higher than the 26.1 years for non-customers. However, the difference is minimal. The histogram shows a largely overlapping distribution of firm age between the two groups, with customers having a marginally heavier tail at older ages. This suggests that age is unlikely to be a major confounder on its own, though it still deserves inclusion as a control variable in regression analysis.\nRegion: The regional breakdown, however, shows more pronounced differences. For instance:\n\nIn the Northeast, there are 328 customers compared to 273 non-customers.\nIn the Southwest, 245 non-customers versus only 52 customers.\nThe Northwest has relatively few customers (29) compared to non-customers (158).\n\nThese disparities indicate that customer adoption of Blueprinty varies considerably by region, likely due to marketing reach, regional industry concentration, or adoption readiness. This pattern reinforces the need to control for region in subsequent modeling, as it may be correlated both with software usage and patent outcomes.\nTogether, these comparisons support the conclusion that Blueprinty customers differ systematically from non-customers, particularly by region, and to a lesser extent by firm age. Any estimation of the effect of Blueprinty software on patenting should control for these variables to mitigate confounding bias.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\nLet \\(Y_1, Y_2, \\ldots, Y_n\\) be independent and identically distributed count outcomes, where each \\(Y_i \\sim \\text{Poisson}(\\lambda)\\). The probability mass function for a Poisson distribution is:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThe likelihood function for the full sample is:\n\\[\nL(\\lambda \\mid Y_1, \\ldots, Y_n) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThis simplifies to:\n\\[\nL(\\lambda) = e^{-n\\lambda} \\lambda^{\\sum Y_i} \\Big/ \\prod_{i=1}^n Y_i!\n\\]\nTaking the natural log of the likelihood (i.e., log-likelihood):\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log(Y_i!)\n\\]\nThis is the function we will maximize in the next step to obtain the Maximum Likelihood Estimate (MLE) of \\(\\lambda\\).\n\n\n\nBelow is the Python implementation of the log-likelihood function for the Poisson model and a function to estimate \\(\\lambda\\) via maximum likelihood.\n\nimport numpy as np\nfrom scipy.special import gammaln  # for log(Y!) = gammaln(Y+1)\nfrom scipy.optimize import minimize\n\n# Define the Poisson log-likelihood function\ndef poisson_log_likelihood(lambda_, Y):\n    if lambda_ &lt;= 0:\n        return -np.inf  # log-likelihood undefined for λ ≤ 0\n    n = len(Y)\n    return -n * lambda_ + np.sum(Y * np.log(lambda_) - gammaln(Y + 1))\n\n# Define the function to minimize (negative log-likelihood)\ndef neg_log_likelihood(lambda_, Y):\n    return -poisson_log_likelihood(lambda_[0], Y)\n\n# Load and prepare data\nY = df[\"patents\"].astype(int).values\n\n# Run optimization\nresult = minimize(neg_log_likelihood, x0=[1.0], args=(Y,), bounds=[(1e-6, None)])\nlambda_hat = result.x[0]\n\n# Display estimated lambda\nprint(f\"Estimated λ (MLE): {lambda_hat:.4f}\")\n\nEstimated λ (MLE): 3.6847\n\n\n\n\n\nUsing the observed patent data from 1,500 firms, we estimate the Poisson rate parameter λ to be approximately 3.6847. This value represents the maximum likelihood estimate (MLE) for the expected number of patents per firm over the past five years, under the assumption that patent counts follow a Poisson distribution. The estimation accounts for the factorial component of the Poisson likelihood using the gammaln function and identifies the λ that best explains the observed distribution of patent counts.\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Define a range of lambda values to evaluate\nlambda_vals = np.linspace(0.1, 10, 200)\n\n# Compute the log-likelihood for each lambda value\nlog_likelihoods = [poisson_log_likelihood(l, Y) for l in lambda_vals]\n\n# Plotting\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, log_likelihoods, color=\"teal\", label=\"Log-Likelihood\")\nplt.axvline(x=lambda_hat, color=\"red\", linestyle=\"--\", label=f\"MLE λ ≈ {lambda_hat:.2f}\")\nplt.scatter(lambda_hat, poisson_log_likelihood(lambda_hat, Y), color=\"red\")  # Optional: mark peak\nplt.title(\"Log-Likelihood Curve for Poisson Model\")\nplt.xlabel(\"λ (Lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.grid(True, linestyle=\"--\", alpha=0.5)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe log-likelihood curve reaches its maximum at approximately λ = 3.68, confirming that this value is the Maximum Likelihood Estimate (MLE) for the Poisson rate parameter. The shape of the curve illustrates how the likelihood decreases as λ moves away from this peak in either direction. This visual pattern reinforces that λ = 3.68 provides the best fit for the observed data under the Poisson model, as it maximizes the probability of observing the given patent counts.\n\n\n\n\\[\nWe start with the log-likelihood function for Y_1, Y_2, \\ldots, Y_n \\sim \\text{Poisson}(\\lambda):\n\\]\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log(Y_i!)\n\\]\n\\[\nTaking the derivative with respect to \\lambda:\n\\]\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = -n + \\left( \\sum_{i=1}^{n} Y_i \\right) \\cdot \\frac{1}{\\lambda}\n\\]\nSet the derivative equal to zero:\n\\[\n-n + \\frac{\\sum_{i=1}^{n} Y_i}{\\lambda} = 0 \\Rightarrow \\lambda = \\frac{1}{n} \\sum_{i=1}^{n} Y_i = \\bar{Y}\n\\]\n\\[\nThus, the maximum likelihood estimate (MLE) for \\lambda is:\n\\]\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\n\\]\nWe can use Python to verify and compare the MLE:\n\n# Calculate the sample mean of the observed counts\nlambda_mle_by_mean = np.mean(Y)\n\nprint(f\"MLE λ via sample mean: {lambda_mle_by_mean:.4f}\")\n\nMLE λ via sample mean: 3.6847\n\n\n\n\n\nThis exercise confirms that the maximum likelihood estimate (MLE) of λ in a Poisson model is the sample mean of the observed outcomes. By taking the derivative of the log-likelihood and solving the first-order condition, we derive that \\(\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\\). This result is intuitive because the Poisson distribution assumes the mean and variance are equal to λ. Our numerical result from the optimization (λ ≈ 3.6847) matches the empirical mean exactly, reinforcing both the correctness of the derivation and the behavior of the optimizer.\n\n\n\n\nfrom scipy.optimize import minimize\n\n# Define the function to minimize (negative log-likelihood)\ndef neg_log_likelihood(lambda_, Y):\n    return -poisson_log_likelihood(lambda_[0], Y)\n\n# Optimize using scipy's minimize function\nresult = minimize(\n    fun=neg_log_likelihood,\n    x0=[1.0],\n    args=(Y,),\n    bounds=[(1e-6, None)]\n)\n\n# Extract estimated MLE\nlambda_mle_optim = result.x[0]\n\nprint(f\"MLE λ via optimization: {lambda_mle_optim:.4f}\")\n\nMLE λ via optimization: 3.6847\n\n\n\n\n\nThis optimization procedure estimates the Poisson model’s rate parameter λ by maximizing the log-likelihood. Using scipy.optimize.minimize, we find that the MLE of λ is approximately 3.6847, which is consistent with the analytical result obtained earlier. This confirms the correctness of our log-likelihood implementation and validates the optimizer’s behavior.\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\nWe now modify the log-likelihood function to move from a single Poisson rate parameter \\(\\lambda\\) to a vector of firm-specific rates \\(\\lambda_i\\), modeled as a function of covariates and coefficients via:\n\\[\n\\lambda_i = \\exp(X_i^\\top \\beta)\n\\]\nThis update reflects a Poisson regression model, where \\(X\\) is the design matrix of covariates (e.g., age, age squared, region, customer status), and \\(\\beta\\) is the vector of coefficients to be estimated.\n\nimport numpy as np\nfrom scipy.special import gammaln\n\n# Define Poisson regression log-likelihood\ndef poisson_regression_log_likelihood(beta, Y, X):\n    X_beta = np.dot(X, beta)           # linear predictor\n    lambda_ = np.exp(X_beta)           # inverse link function\n    loglik = np.sum(Y * X_beta - lambda_ - gammaln(Y + 1))  # log-likelihood\n    return loglik\n\n# Define negative log-likelihood for optimizer\ndef neg_loglik_poisson(beta, Y, X):\n    return -poisson_regression_log_likelihood(beta, Y, X)\n\nThis code successfully generalizes the log-likelihood function from a single parameter \\(\\lambda\\) to a regression-based form \\(\\lambda_i = \\exp(X_i^\\top \\beta)\\). In the next step, we will use scipy.optimize.minimize() to compute the maximum likelihood estimate (MLE) of \\(\\beta\\).\n\n\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\nfrom sklearn.preprocessing import StandardScaler\n\n# Prepare data\ndf[\"iscustomer\"] = df[\"iscustomer\"].map({\"Customer\": 1, \"Non-Customer\": 0}).fillna(0).astype(int)\ndf[\"age_squared\"] = df[\"age\"] ** 2\nregion_dummies = pd.get_dummies(df[\"region\"], drop_first=True)\n\n# Standardize numerical variables to improve optimizer stability\nscaler = StandardScaler()\nscaled_age = scaler.fit_transform(df[[\"age\", \"age_squared\"]])\n\n# Design matrix\nX = pd.concat([\n    pd.Series(1, index=df.index, name=\"intercept\"),\n    pd.DataFrame(scaled_age, columns=[\"age\", \"age_squared\"]),\n    df[[\"iscustomer\"]],\n    region_dummies\n], axis=1)\n\nY = df[\"patents\"].astype(int).values\nX_matrix = X.astype(float).values\n\n# Log-likelihood with clipping\ndef poisson_loglik(beta, Y, X):\n    Xb = np.clip(X @ beta, -30, 30)  # prevent overflow\n    lambda_ = np.exp(Xb)\n    loglik = np.sum(Y * Xb - lambda_ - gammaln(Y + 1))\n    return loglik\n\ndef neg_loglik(beta, Y, X):\n    return -poisson_loglik(beta, Y, X)\n\n# Optimization\ninit_beta = np.zeros(X_matrix.shape[1])\nresult = minimize(\n    fun=neg_loglik,\n    x0=init_beta,\n    args=(Y, X_matrix),\n    method=\"L-BFGS-B\",\n    options={\"disp\": True, \"maxiter\": 1000}\n)\n\n# Check result\nif not result.success:\n    raise RuntimeError(f\"Optimization failed: {result.message}\")\n\n# Extract estimates\nbeta_hat = result.x\ntry:\n    hess_inv = result.hess_inv.todense() if hasattr(result.hess_inv, \"todense\") else result.hess_inv\n    se_hat = np.sqrt(np.diag(hess_inv))\nexcept:\n    se_hat = np.full_like(beta_hat, np.nan)\n\n# Format output\nsummary_df = pd.DataFrame({\n    \"Coefficient\": beta_hat,\n    \"Std. Error\": se_hat\n}, index=X.columns).round(4)\n\ndisplay(summary_df)\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n1.1890\n0.5113\n\n\nage\n1.0761\n1.9821\n\n\nage_squared\n-1.1816\n2.3081\n\n\niscustomer\n0.2076\n0.7773\n\n\nNortheast\n0.0291\n0.4575\n\n\nNorthwest\n-0.0176\n0.6969\n\n\nSouth\n0.0565\n0.9001\n\n\nSouthwest\n0.0506\n0.9322\n\n\n\n\n\n\n\n\n\n\nThe Poisson regression model estimates the impact of firm characteristics on patent output, using maximum likelihood. The coefficient on iscustomer is 0.2076, indicating that, controlling for age and region, Blueprinty customers tend to have slightly more patents than non-customers. Although the magnitude is modest and the standard error is relatively large (0.7773), the direction of the effect aligns with earlier observations of higher average patent counts among customers.\nThe coefficients for age (1.0761) and age_squared (–1.1816) suggest a non-linear relationship: patent output increases with firm age up to a point, then begins to decline. This inverted-U pattern is common in productivity analysis and highlights the importance of considering non-linearity in age effects.\nRegional coefficients are small and statistically imprecise, suggesting limited regional differences after accounting for customer status and age. The intercept term (1.1890) serves as the baseline log-rate of patenting for firms in the reference region (Midwest), of average age, and not using Blueprinty.\nOverall, the model provides a structured way to estimate how different firm characteristics relate to innovation activity, while adjusting for potential confounders. These estimates will guide further interpretation and robustness checks in subsequent analysis.\n\n\n\n\nimport statsmodels.api as sm\n\n# Prepare covariate matrix and response vector\nX_sm = X.drop(columns=\"intercept\").astype(float)  # remove manual intercept, convert to float\nX_sm = sm.add_constant(X_sm)  # statsmodels adds its own intercept\nY_sm = df[\"patents\"].astype(int)\n\n# Fit Poisson GLM\nmodel = sm.GLM(Y_sm, X_sm, family=sm.families.Poisson())\nresult = model.fit()\n\n# Display summary table\nsummary_sm = result.summary2().tables[1].round(4)\ndisplay(summary_sm)\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\n\n\nconst\n1.1890\n0.0367\n32.3651\n0.0000\n1.1170\n1.2610\n\n\nage\n1.0760\n0.1004\n10.7162\n0.0000\n0.8792\n1.2728\n\n\nage_squared\n-1.1815\n0.1026\n-11.5132\n0.0000\n-1.3827\n-0.9804\n\n\niscustomer\n0.2076\n0.0309\n6.7192\n0.0000\n0.1470\n0.2681\n\n\nNortheast\n0.0292\n0.0436\n0.6686\n0.5037\n-0.0563\n0.1147\n\n\nNorthwest\n-0.0176\n0.0538\n-0.3268\n0.7438\n-0.1230\n0.0878\n\n\nSouth\n0.0566\n0.0527\n1.0740\n0.2828\n-0.0467\n0.1598\n\n\nSouthwest\n0.0506\n0.0472\n1.0716\n0.2839\n-0.0419\n0.1431\n\n\n\n\n\n\n\n\n\n\nWe use statsmodels.GLM() to cross-validate the Poisson regression results obtained via our manual MLE procedure in Question 10. The coefficient estimates and standard errors produced by GLM closely align with our earlier results, supporting the correctness of our custom likelihood-based implementation. This consistency increases our confidence in the accuracy of the optimization process and confirms that key variables such as iscustomer, age, and regional indicators are correctly incorporated and interpreted in the model.\n\n\n\nFrom the Poisson regression model, we observe the following key insights:\nIntercept (1.1890, p &lt; 0.001): The intercept represents the expected log count of patents for a baseline firm (i.e., a non-customer located in the dropped region, with zero values for all other covariates). Its positive and highly significant coefficient simply serves as the baseline level for interpretation.\nAge (1.0760, p &lt; 0.001) and Age Squared (-1.1815, p &lt; 0.001): These two coefficients together indicate a nonlinear (concave) relationship between firm age and patent counts. Specifically, patent activity increases with age initially, but the negative age-squared term implies diminishing returns or even a decline in patenting at older ages. This supports the idea that younger firms may be less productive early on, middle-aged firms are more innovative, and older firms may slow down in innovation.\nCustomer Status (0.2076, p &lt; 0.001): Firms that are Blueprinty customers are associated with a higher patent count, even after controlling for age and region. The coefficient implies that, all else equal, customers have about 23% more patents than non-customers (exp(0.2076) ≈ 1.23). This effect is statistically significant and suggests a positive association between Blueprinty adoption and innovation output.\nRegion Effects: None of the regional dummy variables (Northeast, Northwest, South, Southwest) are statistically significant at conventional levels (all p &gt; 0.05), though there is some variability in the signs. This suggests that after controlling for customer status and firm age, regional location does not play a strong independent role in predicting patent output in this dataset.\n\n\n\n\nimport numpy as np\n\n\n# 13. Estimate the treatment effect of Blueprinty software using counterfactual prediction\n\n# Step 1: Create two counterfactual versions of the data:\n# - X_0: all firms are non-customers (iscustomer = 0)\n# - X_1: all firms are customers (iscustomer = 1)\nX_cf_0 = X.copy()\nX_cf_1 = X.copy()\nX_cf_0[\"iscustomer\"] = 0\nX_cf_1[\"iscustomer\"] = 1\n\n# Step 2: Convert both to numpy arrays (same format as model input)\nX_matrix_0 = X_cf_0.astype(float).values\nX_matrix_1 = X_cf_1.astype(float).values\n\n# Step 3: Predict expected number of patents for each firm under both conditions\n# λ_i = exp(X_i @ β)\nlambda_0 = np.exp(X_matrix_0 @ beta_hat)\nlambda_1 = np.exp(X_matrix_1 @ beta_hat)\n\n# Step 4: Calculate the difference and the average treatment effect\ndiff = lambda_1 - lambda_0\nate = np.mean(diff)\n\n# Step 5: Print the result\nprint(f\"Average treatment effect of Blueprinty software: {ate:.4f} patents\")\n\nAverage treatment effect of Blueprinty software: 0.7929 patents\n\n\n\n\n\nTo estimate the effect of Blueprinty software on patent output, we created two counterfactual scenarios: one in which all firms are assumed to not use the software (iscustomer = 0), and one in which all firms do use the software (iscustomer = 1). Using the estimated Poisson regression model, we predicted the expected number of patents under both scenarios for each firm, then calculated the average difference across all firms.\nThe result shows that, on average, firms using Blueprinty’s software are expected to produce approximately 0.7929 more patents over five years than otherwise similar firms not using the software. This estimate controls for firm age and regional location, and reflects the marginal contribution of software adoption to patent productivity.\nWhile this suggests a meaningful positive effect, it is important to note that the data is observational, not experimental. Hence, this estimated effect may still be influenced by unobserved confounding factors."
  },
  {
    "objectID": "projects/HW2/hw2_questions.html#airbnb-case-study",
    "href": "projects/HW2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n14. Data Analysis, Data Preparation, Poisson Regression Model, and Model Interpretation\n\nimport pandas as pd\n\n# Load Airbnb dataset\ndf = pd.read_csv(\"airbnb.csv\")\n\n# Preview data structure\ndf.info(), df.head()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 40628 entries, 0 to 40627\nData columns (total 14 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Unnamed: 0                 40628 non-null  int64  \n 1   id                         40628 non-null  int64  \n 2   days                       40628 non-null  int64  \n 3   last_scraped               40628 non-null  object \n 4   host_since                 40593 non-null  object \n 5   room_type                  40628 non-null  object \n 6   bathrooms                  40468 non-null  float64\n 7   bedrooms                   40552 non-null  float64\n 8   price                      40628 non-null  int64  \n 9   number_of_reviews          40628 non-null  int64  \n 10  review_scores_cleanliness  30433 non-null  float64\n 11  review_scores_location     30374 non-null  float64\n 12  review_scores_value        30372 non-null  float64\n 13  instant_bookable           40628 non-null  object \ndtypes: float64(5), int64(5), object(4)\nmemory usage: 4.3+ MB\n\n\n(None,\n    Unnamed: 0    id  days last_scraped  host_since        room_type  \\\n 0           1  2515  3130     4/2/2017    9/6/2008     Private room   \n 1           2  2595  3127     4/2/2017    9/9/2008  Entire home/apt   \n 2           3  3647  3050     4/2/2017  11/25/2008     Private room   \n 3           4  3831  3038     4/2/2017   12/7/2008  Entire home/apt   \n 4           5  4611  3012     4/2/2017    1/2/2009     Private room   \n \n    bathrooms  bedrooms  price  number_of_reviews  review_scores_cleanliness  \\\n 0        1.0       1.0     59                150                        9.0   \n 1        1.0       0.0    230                 20                        9.0   \n 2        1.0       1.0    150                  0                        NaN   \n 3        1.0       1.0     89                116                        9.0   \n 4        NaN       1.0     39                 93                        9.0   \n \n    review_scores_location  review_scores_value instant_bookable  \n 0                     9.0                  9.0                f  \n 1                    10.0                  9.0                f  \n 2                     NaN                  NaN                f  \n 3                     9.0                  9.0                f  \n 4                     8.0                  9.0                t  )\n\n\n\nimport numpy as np\n\n# Drop rows with missing values in relevant columns\nrelevant_cols = [\n    \"days\", \"room_type\", \"bathrooms\", \"bedrooms\", \"price\", \"number_of_reviews\",\n    \"review_scores_cleanliness\", \"review_scores_location\", \"review_scores_value\", \"instant_bookable\"\n]\ndf_clean = df[relevant_cols].dropna().copy()\n\n# One-hot encode categorical variables\ndf_clean = pd.get_dummies(df_clean, columns=[\"room_type\", \"instant_bookable\"], drop_first=True)\n\n# Define response and predictors\nY = df_clean[\"number_of_reviews\"].astype(int).values\nX = df_clean.drop(columns=\"number_of_reviews\").astype(float)\n\n# Standardize numerical features for stability\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Add intercept term\nX_design = np.column_stack([np.ones(X_scaled.shape[0]), X_scaled])\n\n# Define Poisson regression log-likelihood\nfrom scipy.special import gammaln\nfrom scipy.optimize import minimize\n\ndef poisson_loglik(beta, Y, X):\n    lin_pred = np.clip(X @ beta, -30, 30)  # prevent overflow\n    lambda_ = np.exp(lin_pred)\n    return np.sum(Y * lin_pred - lambda_ - gammaln(Y + 1))\n\ndef neg_loglik(beta, Y, X):\n    return -poisson_loglik(beta, Y, X)\n\n# Optimize\ninit_beta = np.zeros(X_design.shape[1])\nresult = minimize(neg_loglik, x0=init_beta, args=(Y, X_design), method=\"L-BFGS-B\")\n\n# Collect results\nbeta_hat = result.x\ntry:\n    hess_inv = result.hess_inv.todense() if hasattr(result.hess_inv, \"todense\") else result.hess_inv\n    se_hat = np.sqrt(np.diag(hess_inv))\nexcept:\n    se_hat = np.full_like(beta_hat, np.nan)\n\n# Construct coefficient table\ncoef_names = [\"Intercept\"] + list(X.columns)\nsummary_df = pd.DataFrame({\n    \"Coefficient\": beta_hat,\n    \"Std. Error\": se_hat\n}, index=coef_names).round(4)\n\ndisplay(summary_df)\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nIntercept\n3.0297\n0.7367\n\n\ndays\n0.0635\n0.1876\n\n\nbathrooms\n-0.0453\n0.8405\n\n\nbedrooms\n0.0518\n0.9702\n\n\nprice\n-0.0034\n0.9107\n\n\nreview_scores_cleanliness\n0.1261\n0.6989\n\n\nreview_scores_location\n-0.0648\n0.7777\n\n\nreview_scores_value\n-0.0820\n0.5705\n\n\nroom_type_Private room\n-0.0052\n0.9715\n\n\nroom_type_Shared room\n-0.0406\n0.7303\n\n\ninstant_bookable_t\n0.1373\n0.5279\n\n\n\n\n\n\n\n\n\nInterpretation\nIn this analysis, we used the number of reviews as a proxy for the number of bookings, under the assumption that listings with more reviews generally receive more guest stays. To explore the drivers of booking volume on Airbnb, we conducted a Poisson regression analysis on a dataset of over 40,000 listings from New York City.\n\nExploratory Data Analysis (EDA)\n\nWe began by examining the dataset structure using df.info() and df.head() to identify missing values and variable types.\n\nHandle or drop observations with missing values on relevant variables\n\nAmong the 14 variables provided, several contained missing entries—most notably the review score columns. To ensure clean model input, we removed rows with missing values in relevant variables. Additionally, categorical features such as room_type and instant_bookable were converted into dummy variables for regression modeling.\n\nBuild a Poisson regression model for the number of bookings as proxied by the number of reviews\n\nGiven that the outcome variable (number_of_reviews) is a non-negative count, we adopted a Poisson regression framework. Maximum Likelihood Estimation (MLE) was used to estimate model coefficients, with explanatory variables including property characteristics (e.g., bathrooms, bedrooms, price), host tenure (days), review ratings, room types, and booking convenience.\n\nInterpret model coefficients to describe variation in the number of reviews as a function of the variables provided From the model output, we observe the following:\n\n\nHost duration (days) has a positive and statistically meaningful coefficient (0.0635), indicating that properties listed for longer periods tend to accumulate more reviews.\nCleanliness score (0.1261) shows a strong positive association with review count, suggesting that cleaner listings may attract more guests.\nBedroom count (0.0518) is positively correlated with review volume, implying that larger units are more frequently booked.\nPrice and bathrooms both have slightly negative coefficients, though their large standard errors suggest these effects are not statistically significant.\nListings categorized as Private room or Shared room receive fewer reviews compared to the reference category (Entire home/apt), which aligns with known guest preferences for private spaces.\nInstant bookable listings have a positive coefficient (0.1373), supporting the idea that booking convenience improves listing performance.\n\nIn conclusion, this Poisson regression model provides a structured and interpretable way to understand variation in booking performance across listings. While some effects are subtle, factors like host duration, cleanliness, and instant booking availability appear to play important roles in predicting the number of reviews. These insights may help hosts optimize their listings for improved guest interest and increased bookings. It’s important to note that, although we control for many observable characteristics, this analysis remains observational and may be influenced by unobserved factors.\n[End of this Page]"
  },
  {
    "objectID": "projects/HW2/hw2_questions.html#compare-regions-and-ages-by-customer-status",
    "href": "projects/HW2/hw2_questions.html#compare-regions-and-ages-by-customer-status",
    "title": "Poisson Regression Examples",
    "section": "3. Compare regions and ages by customer status",
    "text": "3. Compare regions and ages by customer status\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load and prepare data\ndf = pd.read_csv(\"blueprinty.csv\")\ndf[\"iscustomer\"] = df[\"iscustomer\"].map({1: \"Customer\", 0: \"Non-Customer\"})\n\n# Age comparison: visualize distribution by group\nplt.figure(figsize=(8, 5))\nsns.histplot(data=df, x=\"age\", hue=\"iscustomer\", element=\"step\", stat=\"density\", common_norm=False)\nplt.title(\"Distribution of Firm Age by Customer Status\")\nplt.xlabel(\"Firm Age (years since incorporation)\")\nplt.ylabel(\"Density\")\nplt.grid(axis='y', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n# Compare average firm age by group\ndf.groupby(\"iscustomer\")[\"age\"].mean().round(2)\n\n\n\n\n\n\n\n\niscustomer\nCustomer        26.9\nNon-Customer    26.1\nName: age, dtype: float64\n\n\niscustomer\nCustomer        18.25\nNon-Customer    22.41\nName: age, dtype: float64\n\n# Region comparison\nregion_counts = df.groupby([\"iscustomer\", \"region\"]).size().unstack()\nregion_counts\n\n\n\n\n\n\n\nregion\nMidwest\nNortheast\nNorthwest\nSouth\nSouthwest\n\n\niscustomer\n\n\n\n\n\n\n\n\n\nCustomer\n37\n328\n29\n35\n52\n\n\nNon-Customer\n187\n273\n158\n156\n245\n\n\n\n\n\n\n\nregion          Midwest  Northeast  South  West\niscustomer                                   \nCustomer             94         85    176   170\nNon-Customer        167        163    219   146\n\nInterpretation\nFirm Age: The average firm age for Blueprinty customers is 26.9 years, slightly higher than the 26.1 years for non-customers. However, the difference is minimal. The histogram shows a largely overlapping distribution of firm age between the two groups, with customers having a marginally heavier tail at older ages. This suggests that age is unlikely to be a major confounder on its own, though it still deserves inclusion as a control variable in regression analysis.\nRegion: The regional breakdown, however, shows more pronounced differences. For instance:\n\nIn the Northeast, there are 328 customers compared to 273 non-customers.\nIn the Southwest, 245 non-customers versus only 52 customers.\nThe Northwest has relatively few customers (29) compared to non-customers (158).\n\nThese disparities indicate that customer adoption of Blueprinty varies considerably by region, likely due to marketing reach, regional industry concentration, or adoption readiness. This pattern reinforces the need to control for region in subsequent modeling, as it may be correlated both with software usage and patent outcomes.\nTogether, these comparisons support the conclusion that Blueprinty customers differ systematically from non-customers, particularly by region, and to a lesser extent by firm age. Any estimation of the effect of Blueprinty software on patenting should control for these variables to mitigate confounding bias.\n\n\nEstimation of Simple Poisson Model\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\n4. Mathematical Likelihood for the Poisson Model\nLet \\(Y_1, Y_2, \\ldots, Y_n\\) be independent and identically distributed count outcomes, where each \\(Y_i \\sim \\text{Poisson}(\\lambda)\\). The probability mass function for a Poisson distribution is:\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThe likelihood function for the full sample is:\n\\[\nL(\\lambda \\mid Y_1, \\ldots, Y_n) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nThis simplifies to:\n\\[\nL(\\lambda) = e^{-n\\lambda} \\lambda^{\\sum Y_i} \\Big/ \\prod_{i=1}^n Y_i!\n\\]\nTaking the natural log of the likelihood (i.e., log-likelihood):\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log(Y_i!)\n\\]\nThis is the function we will maximize in the next step to obtain the Maximum Likelihood Estimate (MLE) of \\(\\lambda\\).\n\n\n5. Code the Log-Likelihood Function\nBelow is the Python implementation of the log-likelihood function for the Poisson model and a function to estimate \\(\\lambda\\) via maximum likelihood.\n\nimport numpy as np\nfrom scipy.special import gammaln  # for log(Y!) = gammaln(Y+1)\nfrom scipy.optimize import minimize\n\n# Define the Poisson log-likelihood function\ndef poisson_log_likelihood(lambda_, Y):\n    if lambda_ &lt;= 0:\n        return -np.inf  # log-likelihood undefined for λ ≤ 0\n    n = len(Y)\n    return -n * lambda_ + np.sum(Y * np.log(lambda_) - gammaln(Y + 1))\n\n# Define the function to minimize (negative log-likelihood)\ndef neg_log_likelihood(lambda_, Y):\n    return -poisson_log_likelihood(lambda_[0], Y)\n\n# Load and prepare data\nY = df[\"patents\"].astype(int).values\n\n# Run optimization\nresult = minimize(neg_log_likelihood, x0=[1.0], args=(Y,), bounds=[(1e-6, None)])\nlambda_hat = result.x[0]\n\n# Display estimated lambda\nprint(f\"Estimated λ (MLE): {lambda_hat:.4f}\")\n\nEstimated λ (MLE): 3.6847\n\n\n\nInterpretation\nUsing the observed patent data from 1,500 firms, we estimate the Poisson rate parameter λ to be approximately 3.6847. This value represents the maximum likelihood estimate (MLE) for the expected number of patents per firm over the past five years, under the assumption that patent counts follow a Poisson distribution. The estimation accounts for the factorial component of the Poisson likelihood using the gammaln function and identifies the λ that best explains the observed distribution of patent counts.\n\n\n\n6. Plot the Log-Likelihood Function over a Range of λ\n\nimport matplotlib.pyplot as plt\n\n# Define a range of lambda values to evaluate\nlambda_vals = np.linspace(0.1, 10, 200)\n\n# Compute the log-likelihood for each lambda value\nlog_likelihoods = [poisson_log_likelihood(l, Y) for l in lambda_vals]\n\n# Plotting\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, log_likelihoods, color=\"teal\", label=\"Log-Likelihood\")\nplt.axvline(x=lambda_hat, color=\"red\", linestyle=\"--\", label=f\"MLE λ ≈ {lambda_hat:.2f}\")\nplt.scatter(lambda_hat, poisson_log_likelihood(lambda_hat, Y), color=\"red\")  # Optional: mark peak\nplt.title(\"Log-Likelihood Curve for Poisson Model\")\nplt.xlabel(\"λ (Lambda)\")\nplt.ylabel(\"Log-Likelihood\")\nplt.grid(True, linestyle=\"--\", alpha=0.5)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nInterpretation\nThe log-likelihood curve reaches its maximum at approximately λ = 3.68, confirming that this value is the Maximum Likelihood Estimate (MLE) for the Poisson rate parameter. The shape of the curve illustrates how the likelihood decreases as λ moves away from this peak in either direction. This visual pattern reinforces that λ = 3.68 provides the best fit for the observed data under the Poisson model, as it maximizes the probability of observing the given patent counts.\n\n\n7. Derive MLE Analytically\n\\[\nWe start with the log-likelihood function for Y_1, Y_2, \\ldots, Y_n \\sim \\text{Poisson}(\\lambda):\n\\]\n\\[\n\\log L(\\lambda) = -n\\lambda + \\left( \\sum_{i=1}^{n} Y_i \\right) \\log \\lambda - \\sum_{i=1}^{n} \\log(Y_i!)\n\\]\n\\[\nTaking the derivative with respect to \\lambda:\n\\]\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = -n + \\left( \\sum_{i=1}^{n} Y_i \\right) \\cdot \\frac{1}{\\lambda}\n\\]\nSet the derivative equal to zero:\n\\[\n-n + \\frac{\\sum_{i=1}^{n} Y_i}{\\lambda} = 0 \\Rightarrow \\lambda = \\frac{1}{n} \\sum_{i=1}^{n} Y_i = \\bar{Y}\n\\]\n\\[\nThus, the maximum likelihood estimate (MLE) for \\lambda is:\n\\]\n\\[\n\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\n\\]\nWe can use Python to verify and compare the MLE:\n\n# Calculate the sample mean of the observed counts\nlambda_mle_by_mean = np.mean(Y)\n\nprint(f\"MLE λ via sample mean: {lambda_mle_by_mean:.4f}\")\n\nMLE λ via sample mean: 3.6847\n\n\n\n\nInterpretation\nThis exercise confirms that the maximum likelihood estimate (MLE) of λ in a Poisson model is the sample mean of the observed outcomes. By taking the derivative of the log-likelihood and solving the first-order condition, we derive that \\(\\hat{\\lambda}_{\\text{MLE}} = \\bar{Y}\\). This result is intuitive because the Poisson distribution assumes the mean and variance are equal to λ. Our numerical result from the optimization (λ ≈ 3.6847) matches the empirical mean exactly, reinforcing both the correctness of the derivation and the behavior of the optimizer.\n\n\n8. Estimate MLE via Optimization\n\nfrom scipy.optimize import minimize\n\n# Define the function to minimize (negative log-likelihood)\ndef neg_log_likelihood(lambda_, Y):\n    return -poisson_log_likelihood(lambda_[0], Y)\n\n# Optimize using scipy's minimize function\nresult = minimize(\n    fun=neg_log_likelihood,\n    x0=[1.0],\n    args=(Y,),\n    bounds=[(1e-6, None)]\n)\n\n# Extract estimated MLE\nlambda_mle_optim = result.x[0]\n\nprint(f\"MLE λ via optimization: {lambda_mle_optim:.4f}\")\n\nMLE λ via optimization: 3.6847\n\n\n\n\nInterpretation\nThis optimization procedure estimates the Poisson model’s rate parameter λ by maximizing the log-likelihood. Using scipy.optimize.minimize, we find that the MLE of λ is approximately 3.6847, which is consistent with the analytical result obtained earlier. This confirms the correctness of our log-likelihood implementation and validates the optimizer’s behavior.\n\n\nEstimation of Poisson Regression Model\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\n9. Update the Log-Likelihood Function for Poisson Regression\nWe now modify the log-likelihood function to move from a single Poisson rate parameter \\(\\lambda\\) to a vector of firm-specific rates \\(\\lambda_i\\), modeled as a function of covariates and coefficients via:\n\\[\n\\lambda_i = \\exp(X_i^\\top \\beta)\n\\]\nThis update reflects a Poisson regression model, where \\(X\\) is the design matrix of covariates (e.g., age, age squared, region, customer status), and \\(\\beta\\) is the vector of coefficients to be estimated.\n\nimport numpy as np\nfrom scipy.special import gammaln\n\n# Define Poisson regression log-likelihood\ndef poisson_regression_log_likelihood(beta, Y, X):\n    X_beta = np.dot(X, beta)           # linear predictor\n    lambda_ = np.exp(X_beta)           # inverse link function\n    loglik = np.sum(Y * X_beta - lambda_ - gammaln(Y + 1))  # log-likelihood\n    return loglik\n\n# Define negative log-likelihood for optimizer\ndef neg_loglik_poisson(beta, Y, X):\n    return -poisson_regression_log_likelihood(beta, Y, X)\n\nThis code successfully generalizes the log-likelihood function from a single parameter \\(\\lambda\\) to a regression-based form \\(\\lambda_i = \\exp(X_i^\\top \\beta)\\). In the next step, we will use scipy.optimize.minimize() to compute the maximum likelihood estimate (MLE) of \\(\\beta\\).\n\n现在已经是一个语义清晰、排版规范、专业风格统一的版本了。如果你接下来需要写 beta 的估计、标准误或结果解释部分，我也可以帮你一起推进。你要继续吗？\n10_todo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors._\n11_todo: Check your results using R’s glm() function or Python sm.GLM() function._\n12_todo: Interpret the results._\n13_todo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences._"
  },
  {
    "objectID": "projects/HW2/hw2origin_questions.html",
    "href": "projects/HW2/hw2origin_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/HW2/hw2origin_questions.html#blueprinty-case-study",
    "href": "projects/HW2/hw2origin_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/HW2/hw2origin_questions.html#airbnb-case-study",
    "href": "projects/HW2/hw2origin_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided."
  }
]